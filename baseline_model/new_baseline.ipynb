{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import json\n",
    "import seaborn as sns\n",
    "import os\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "import plotly.express as px\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, Dataset, DataLoader, random_split\n",
    "from torch.nn import functional as F\n",
    "from torch.optim import lr_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class config:\n",
    "    train_file = './stanford-covid-vaccine/train.json'\n",
    "    test_file = './stanford-covid-vaccine/test.json'\n",
    "    pretrain_dir = './baseline_model'\n",
    "    sample_submission = './stanford-covid-vaccine/sample_submission.csv'\n",
    "    learning_rate = 0.001\n",
    "    batch_size = 64\n",
    "    n_epoch = 200\n",
    "    n_split = 5\n",
    "    filter_noise = True\n",
    "    patience= 10\n",
    "    seed = 1234\n",
    "    pooling_kernel = 3\n",
    "    cnn_dropout_rate = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter:\n",
    "    \"\"\"\n",
    "    Computes and stores the average and current value\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=1234):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "seed_everything(config.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_cols = ['reactivity', 'deg_Mg_pH10', 'deg_pH10', 'deg_Mg_50C', 'deg_50C']\n",
    "train = pd.read_json(config.train_file, lines=True)\n",
    "\n",
    "if config.filter_noise:\n",
    "    train = train[train.signal_to_noise > 1]\n",
    "    \n",
    "test = pd.read_json(config.test_file, lines=True)\n",
    "sample_df = pd.read_csv(config.sample_submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(data,dict_):\n",
    "    one_hot_encoding = np.zeros([data.shape[0],len(data[0]),len(dict_)])\n",
    "    for i in range(len(data)):\n",
    "        d = data[i]\n",
    "        for j in range(len(d)):\n",
    "            idx = dict_[d[j]]\n",
    "            one_hot_encoding[i,j,idx] = 1\n",
    "    return one_hot_encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(input_data):\n",
    "    one_hot_encoding = []\n",
    "    sequence_dict = {\"A\":0,\"U\":1,\"C\":2,\"G\":3}\n",
    "    structure_dict = {\"(\":0,\")\":1,\".\":2}\n",
    "    loop_dict = {\"B\":0,\"E\":1,\"H\":2,\"I\":3,\"M\":4,\"S\":5,\"X\":6}\n",
    "    cols = ['sequence','structure', 'predicted_loop_type']\n",
    "    for c in cols:\n",
    "        data = input_data[c].values\n",
    "        if c == \"sequence\":\n",
    "            one_hot_encoding += [encode(data,sequence_dict)]\n",
    "        elif c == \"structure\":\n",
    "            one_hot_encoding += [encode(data,structure_dict)]\n",
    "        else: \n",
    "            one_hot_encoding += [encode(data,loop_dict)]\n",
    "    one_hot_encoding = np.concatenate(one_hot_encoding,axis=2)\n",
    "    return one_hot_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs = one_hot_encoding(train)\n",
    "train_labels = np.array(train[pred_cols].values.tolist()).transpose((0, 2, 1))\n",
    "\n",
    "train_inputs = torch.tensor(train_inputs, dtype=torch.float32)\n",
    "train_labels = torch.tensor(train_labels, dtype=torch.float32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.kernel = kernel\n",
    "        self.cnn = nn.Conv1d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel, padding=kernel//2).cuda()\n",
    "        self.norm = nn.LayerNorm(out_channels).cuda()\n",
    "        self.pooling = nn.AvgPool1d(config.pooling_kernel,1,padding=config.pooling_kernel//2)\n",
    "        self.dropout = nn.Dropout(p=config.cnn_dropout_rate).cuda()\n",
    "        \n",
    "    def forward(self, feature_embedding):\n",
    "        f = feature_embedding.permute([0,2,1])\n",
    "        f = self.cnn(f)\n",
    "        f = F.leaky_relu(f)\n",
    "        f = self.pooling(f)\n",
    "        f = f.permute([0,2,1])\n",
    "        f = self.norm(f)\n",
    "        f = self.dropout(f)\n",
    "        \n",
    "        return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, seq_len=107, pred_len=68):\n",
    "        '''\n",
    "        K: number of GCN layers\n",
    "        aggregator: type of aggregator function\n",
    "        '''\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.pred_len = pred_len\n",
    "        self.CNN1 = CNN(in_channels=14,out_channels=128,kernel=5)\n",
    "        self.CNN2 = CNN(in_channels=128,out_channels=64,kernel=9)\n",
    "        self.CNN3 = CNN(in_channels=64,out_channels=32,kernel=17)\n",
    "        self.linear_layer1 = nn.Linear(in_features=32, \n",
    "                                out_features=5)\n",
    "        \n",
    "    def forward(self, input_):\n",
    "        cnn_output1 = self.CNN1(input_)\n",
    "        cnn_output2 = self.CNN2(cnn_output1)\n",
    "        cnn_output3 = self.CNN3(cnn_output2)\n",
    "        truncated = cnn_output3[:, :self.pred_len,:]\n",
    "        truncated = self.linear_layer1(truncated)\n",
    "        \n",
    "        return truncated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(epoch, model, train_loader, criterion, optimizer):\n",
    "    model.train()\n",
    "    model.zero_grad()\n",
    "    train_loss = AverageMeter()\n",
    "    \n",
    "    for index, (input_, label) in enumerate(train_loader):\n",
    "        input_ = input_.cuda()\n",
    "        label = label.cuda()\n",
    "        preds = model(input_)\n",
    "        \n",
    "        loss = criterion(preds, label)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss.update(loss.item())\n",
    "    \n",
    "    print(f\"Train loss {train_loss.avg}\")\n",
    "    return train_loss.avg\n",
    "    \n",
    "def eval_fn(epoch, model, valid_loader, criterion):\n",
    "    model.eval()\n",
    "    eval_loss = AverageMeter()\n",
    "    \n",
    "    for index, (input_, label) in enumerate(valid_loader):\n",
    "        input_ = input_.cuda()\n",
    "        label = label.cuda()\n",
    "        preds = model(input_)\n",
    "        \n",
    "        loss = criterion(preds, label)\n",
    "        eval_loss.update(loss.item())\n",
    "    \n",
    "    print(f\"Valid loss {eval_loss.avg}\")\n",
    "    return eval_loss.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(fold, train_loader, valid_loader):\n",
    "    model = Net()\n",
    "    model.cuda()\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(params=model.parameters(), lr=config.learning_rate, weight_decay=0.0)\n",
    "    \n",
    "    eval_loss_increase_step = 0\n",
    "    train_losses = []\n",
    "    eval_losses = []\n",
    "    for epoch in range(config.n_epoch):\n",
    "        print('#################')\n",
    "        print('###Epoch:', epoch)\n",
    "        \n",
    "        train_loss = train_fn(epoch, model, train_loader, criterion, optimizer)\n",
    "        eval_loss = eval_fn(epoch, model, valid_loader, criterion)\n",
    "        train_losses.append(train_loss)\n",
    "        eval_losses.append(eval_loss)\n",
    "        \n",
    "        # check if should early stop\n",
    "        if len(eval_losses) == 2:\n",
    "            previous_eval_loss = eval_losses[0]\n",
    "        if len(eval_losses) >= 2:\n",
    "            if eval_loss > previous_eval_loss:\n",
    "                eval_loss_increase_step += 1\n",
    "            else: \n",
    "                # save the model if it is better than previous step\n",
    "                torch.save(model.state_dict(), f'{config.pretrain_dir}/baseline_{fold}.pt')\n",
    "                eval_loss_increase_step = 0\n",
    "                previous_eval_loss=eval_loss\n",
    "                \n",
    "            print(\"previous_eval_loss %s\"%previous_eval_loss)\n",
    "        if eval_loss_increase_step >= config.patience:\n",
    "            print(\"early stop the model at Epoch: \", epoch)\n",
    "            del model\n",
    "            break\n",
    "            \n",
    "        \n",
    "#     torch.save(model.state_dict(), f'{config.pretrain_dir}/gcn_gru_{fold}.pt')\n",
    "    return train_losses, eval_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#################\n",
      "###Epoch: 0\n",
      "Train loss 0.29530018347280995\n",
      "Valid loss 0.214090319616454\n",
      "#################\n",
      "###Epoch: 1\n",
      "Train loss 0.2159131340406559\n",
      "Valid loss 0.19492762642247335\n",
      "previous_eval_loss 0.19492762642247335\n",
      "#################\n",
      "###Epoch: 2\n",
      "Train loss 0.19862050811449686\n",
      "Valid loss 0.18405300378799438\n",
      "previous_eval_loss 0.18405300378799438\n",
      "#################\n",
      "###Epoch: 3\n",
      "Train loss 0.18505494627687666\n",
      "Valid loss 0.17527470205511367\n",
      "previous_eval_loss 0.17527470205511367\n",
      "#################\n",
      "###Epoch: 4\n",
      "Train loss 0.17449305565268905\n",
      "Valid loss 0.16804164435182298\n",
      "previous_eval_loss 0.16804164435182298\n",
      "#################\n",
      "###Epoch: 5\n",
      "Train loss 0.1661762970465201\n",
      "Valid loss 0.16858275021825517\n",
      "previous_eval_loss 0.16804164435182298\n",
      "#################\n",
      "###Epoch: 6\n",
      "Train loss 0.15856283516795547\n",
      "Valid loss 0.15909463592938014\n",
      "previous_eval_loss 0.15909463592938014\n",
      "#################\n",
      "###Epoch: 7\n",
      "Train loss 0.1524307617434749\n",
      "Valid loss 0.15309140299047744\n",
      "previous_eval_loss 0.15309140299047744\n",
      "#################\n",
      "###Epoch: 8\n",
      "Train loss 0.14899736808405983\n",
      "Valid loss 0.14885973291737692\n",
      "previous_eval_loss 0.14885973291737692\n",
      "#################\n",
      "###Epoch: 9\n",
      "Train loss 0.14322395898677684\n",
      "Valid loss 0.14413507069860185\n",
      "previous_eval_loss 0.14413507069860185\n",
      "#################\n",
      "###Epoch: 10\n",
      "Train loss 0.13780637057843032\n",
      "Valid loss 0.14156300042356765\n",
      "previous_eval_loss 0.14156300042356765\n",
      "#################\n",
      "###Epoch: 11\n",
      "Train loss 0.1364764642936212\n",
      "Valid loss 0.14056600417409623\n",
      "previous_eval_loss 0.14056600417409623\n",
      "#################\n",
      "###Epoch: 12\n",
      "Train loss 0.13327967706653807\n",
      "Valid loss 0.13520245254039764\n",
      "previous_eval_loss 0.13520245254039764\n",
      "#################\n",
      "###Epoch: 13\n",
      "Train loss 0.1302229646179411\n",
      "Valid loss 0.13274591522557394\n",
      "previous_eval_loss 0.13274591522557394\n",
      "#################\n",
      "###Epoch: 14\n",
      "Train loss 0.1273465300047839\n",
      "Valid loss 0.13098818063735962\n",
      "previous_eval_loss 0.13098818063735962\n",
      "#################\n",
      "###Epoch: 15\n",
      "Train loss 0.12647370856117318\n",
      "Valid loss 0.12887111412627356\n",
      "previous_eval_loss 0.12887111412627356\n",
      "#################\n",
      "###Epoch: 16\n",
      "Train loss 0.12373324594012013\n",
      "Valid loss 0.12884479654686792\n",
      "previous_eval_loss 0.12884479654686792\n",
      "#################\n",
      "###Epoch: 17\n",
      "Train loss 0.12047794378466076\n",
      "Valid loss 0.12516486325434276\n",
      "previous_eval_loss 0.12516486325434276\n",
      "#################\n",
      "###Epoch: 18\n",
      "Train loss 0.12009407883441006\n",
      "Valid loss 0.12481063285044261\n",
      "previous_eval_loss 0.12481063285044261\n",
      "#################\n",
      "###Epoch: 19\n",
      "Train loss 0.11855418759363669\n",
      "Valid loss 0.12301633507013321\n",
      "previous_eval_loss 0.12301633507013321\n",
      "#################\n",
      "###Epoch: 20\n",
      "Train loss 0.11721565712381292\n",
      "Valid loss 0.11998650857380458\n",
      "previous_eval_loss 0.11998650857380458\n",
      "#################\n",
      "###Epoch: 21\n",
      "Train loss 0.11511380639341143\n",
      "Valid loss 0.121015336896692\n",
      "previous_eval_loss 0.11998650857380458\n",
      "#################\n",
      "###Epoch: 22\n",
      "Train loss 0.11406827800803715\n",
      "Valid loss 0.11778141664607185\n",
      "previous_eval_loss 0.11778141664607185\n",
      "#################\n",
      "###Epoch: 23\n",
      "Train loss 0.11158273037936953\n",
      "Valid loss 0.11639394504683358\n",
      "previous_eval_loss 0.11639394504683358\n",
      "#################\n",
      "###Epoch: 24\n",
      "Train loss 0.11136068017394454\n",
      "Valid loss 0.1143638055239405\n",
      "previous_eval_loss 0.1143638055239405\n",
      "#################\n",
      "###Epoch: 25\n",
      "Train loss 0.10926619834370083\n",
      "Valid loss 0.11394841117518288\n",
      "previous_eval_loss 0.11394841117518288\n",
      "#################\n",
      "###Epoch: 26\n",
      "Train loss 0.10711278904367376\n",
      "Valid loss 0.11821604413645607\n",
      "previous_eval_loss 0.11394841117518288\n",
      "#################\n",
      "###Epoch: 27\n",
      "Train loss 0.10704590131839116\n",
      "Valid loss 0.1118147958602224\n",
      "previous_eval_loss 0.1118147958602224\n",
      "#################\n",
      "###Epoch: 28\n",
      "Train loss 0.10482371515697902\n",
      "Valid loss 0.11136389736618314\n",
      "previous_eval_loss 0.11136389736618314\n",
      "#################\n",
      "###Epoch: 29\n",
      "Train loss 0.10448352109502863\n",
      "Valid loss 0.11022382761750903\n",
      "previous_eval_loss 0.11022382761750903\n",
      "#################\n",
      "###Epoch: 30\n",
      "Train loss 0.10240189427578891\n",
      "Valid loss 0.10996026865073613\n",
      "previous_eval_loss 0.10996026865073613\n",
      "#################\n",
      "###Epoch: 31\n",
      "Train loss 0.10218556804789437\n",
      "Valid loss 0.10908356841121401\n",
      "previous_eval_loss 0.10908356841121401\n",
      "#################\n",
      "###Epoch: 32\n",
      "Train loss 0.10103298585723948\n",
      "Valid loss 0.10859964681523186\n",
      "previous_eval_loss 0.10859964681523186\n",
      "#################\n",
      "###Epoch: 33\n",
      "Train loss 0.1001035248239835\n",
      "Valid loss 0.10734365454741887\n",
      "previous_eval_loss 0.10734365454741887\n",
      "#################\n",
      "###Epoch: 34\n",
      "Train loss 0.09854231305696347\n",
      "Valid loss 0.10709582482065473\n",
      "previous_eval_loss 0.10709582482065473\n",
      "#################\n",
      "###Epoch: 35\n",
      "Train loss 0.09774402998111865\n",
      "Valid loss 0.10678755172661372\n",
      "previous_eval_loss 0.10678755172661372\n",
      "#################\n",
      "###Epoch: 36\n",
      "Train loss 0.098757220087228\n",
      "Valid loss 0.10710922202893666\n",
      "previous_eval_loss 0.10678755172661372\n",
      "#################\n",
      "###Epoch: 37\n",
      "Train loss 0.09621916711330414\n",
      "Valid loss 0.10508647561073303\n",
      "previous_eval_loss 0.10508647561073303\n",
      "#################\n",
      "###Epoch: 38\n",
      "Train loss 0.09547138214111328\n",
      "Valid loss 0.10391932406595775\n",
      "previous_eval_loss 0.10391932406595775\n",
      "#################\n",
      "###Epoch: 39\n",
      "Train loss 0.09496496479820322\n",
      "Valid loss 0.10279262491634913\n",
      "previous_eval_loss 0.10279262491634913\n",
      "#################\n",
      "###Epoch: 40\n",
      "Train loss 0.09384871577775036\n",
      "Valid loss 0.1017409839800426\n",
      "previous_eval_loss 0.1017409839800426\n",
      "#################\n",
      "###Epoch: 41\n",
      "Train loss 0.09391992208030489\n",
      "Valid loss 0.10368095764092036\n",
      "previous_eval_loss 0.1017409839800426\n",
      "#################\n",
      "###Epoch: 42\n",
      "Train loss 0.09294881561288128\n",
      "Valid loss 0.10166044746126447\n",
      "previous_eval_loss 0.10166044746126447\n",
      "#################\n",
      "###Epoch: 43\n",
      "Train loss 0.09191056230553875\n",
      "Valid loss 0.10128888594252723\n",
      "previous_eval_loss 0.10128888594252723\n",
      "#################\n",
      "###Epoch: 44\n",
      "Train loss 0.09071549110942417\n",
      "Valid loss 0.10064574969666344\n",
      "previous_eval_loss 0.10064574969666344\n",
      "#################\n",
      "###Epoch: 45\n",
      "Train loss 0.09028643010943024\n",
      "Valid loss 0.10003099803413663\n",
      "previous_eval_loss 0.10003099803413663\n",
      "#################\n",
      "###Epoch: 46\n",
      "Train loss 0.09011756380399068\n",
      "Valid loss 0.09977102492536817\n",
      "previous_eval_loss 0.09977102492536817\n",
      "#################\n",
      "###Epoch: 47\n",
      "Train loss 0.08894254129242014\n",
      "Valid loss 0.0992868042417935\n",
      "previous_eval_loss 0.0992868042417935\n",
      "#################\n",
      "###Epoch: 48\n",
      "Train loss 0.08681706035578693\n",
      "Valid loss 0.09744907596281596\n",
      "previous_eval_loss 0.09744907596281596\n",
      "#################\n",
      "###Epoch: 49\n",
      "Train loss 0.08703707296539236\n",
      "Valid loss 0.09891926710094724\n",
      "previous_eval_loss 0.09744907596281596\n",
      "#################\n",
      "###Epoch: 50\n",
      "Train loss 0.08742252047415133\n",
      "Valid loss 0.09783118431057249\n",
      "previous_eval_loss 0.09744907596281596\n",
      "#################\n",
      "###Epoch: 51\n",
      "Train loss 0.08551036759659096\n",
      "Valid loss 0.09830211315836225\n",
      "previous_eval_loss 0.09744907596281596\n",
      "#################\n",
      "###Epoch: 52\n",
      "Train loss 0.08654616414396851\n",
      "Valid loss 0.10009113486324038\n",
      "previous_eval_loss 0.09744907596281596\n",
      "#################\n",
      "###Epoch: 53\n",
      "Train loss 0.08448778782729749\n",
      "Valid loss 0.09621311298438481\n",
      "previous_eval_loss 0.09621311298438481\n",
      "#################\n",
      "###Epoch: 54\n",
      "Train loss 0.08517470155601148\n",
      "Valid loss 0.09751209723097938\n",
      "previous_eval_loss 0.09621311298438481\n",
      "#################\n",
      "###Epoch: 55\n",
      "Train loss 0.084324744840463\n",
      "Valid loss 0.0956714419381959\n",
      "previous_eval_loss 0.0956714419381959\n",
      "#################\n",
      "###Epoch: 56\n",
      "Train loss 0.08316767602055161\n",
      "Valid loss 0.09650824644735881\n",
      "previous_eval_loss 0.0956714419381959\n",
      "#################\n",
      "###Epoch: 57\n",
      "Train loss 0.0822040816700017\n",
      "Valid loss 0.09571298850434166\n",
      "previous_eval_loss 0.0956714419381959\n",
      "#################\n",
      "###Epoch: 58\n",
      "Train loss 0.08168506429151252\n",
      "Valid loss 0.09495566146714347\n",
      "previous_eval_loss 0.09495566146714347\n",
      "#################\n",
      "###Epoch: 59\n",
      "Train loss 0.08189987611991388\n",
      "Valid loss 0.0945505393402917\n",
      "previous_eval_loss 0.0945505393402917\n",
      "#################\n",
      "###Epoch: 60\n",
      "Train loss 0.08032653673931404\n",
      "Valid loss 0.09378405553953988\n",
      "previous_eval_loss 0.09378405553953988\n",
      "#################\n",
      "###Epoch: 61\n",
      "Train loss 0.08014410651392406\n",
      "Valid loss 0.09444355964660645\n",
      "previous_eval_loss 0.09378405553953988\n",
      "#################\n",
      "###Epoch: 62\n",
      "Train loss 0.08118364214897156\n",
      "Valid loss 0.09441277384757996\n",
      "previous_eval_loss 0.09378405553953988\n",
      "#################\n",
      "###Epoch: 63\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.07970534734151981\n",
      "Valid loss 0.09438819863966533\n",
      "previous_eval_loss 0.09378405553953988\n",
      "#################\n",
      "###Epoch: 64\n",
      "Train loss 0.07923038138283624\n",
      "Valid loss 0.0924643480351993\n",
      "previous_eval_loss 0.0924643480351993\n",
      "#################\n",
      "###Epoch: 65\n",
      "Train loss 0.07777676593374323\n",
      "Valid loss 0.0933568509561675\n",
      "previous_eval_loss 0.0924643480351993\n",
      "#################\n",
      "###Epoch: 66\n",
      "Train loss 0.07898548300619479\n",
      "Valid loss 0.09260428590433938\n",
      "previous_eval_loss 0.0924643480351993\n",
      "#################\n",
      "###Epoch: 67\n",
      "Train loss 0.07712562409815965\n",
      "Valid loss 0.09248917869159154\n",
      "previous_eval_loss 0.0924643480351993\n",
      "#################\n",
      "###Epoch: 68\n",
      "Train loss 0.07683730125427246\n",
      "Valid loss 0.09200175319399152\n",
      "previous_eval_loss 0.09200175319399152\n",
      "#################\n",
      "###Epoch: 69\n",
      "Train loss 0.07749684210176822\n",
      "Valid loss 0.09230485877820424\n",
      "previous_eval_loss 0.09200175319399152\n",
      "#################\n",
      "###Epoch: 70\n",
      "Train loss 0.07741922195310946\n",
      "Valid loss 0.09202673499073301\n",
      "previous_eval_loss 0.09200175319399152\n",
      "#################\n",
      "###Epoch: 71\n",
      "Train loss 0.0767531861309652\n",
      "Valid loss 0.0916893482208252\n",
      "previous_eval_loss 0.0916893482208252\n",
      "#################\n",
      "###Epoch: 72\n",
      "Train loss 0.07651921968769144\n",
      "Valid loss 0.0910106748342514\n",
      "previous_eval_loss 0.0910106748342514\n",
      "#################\n",
      "###Epoch: 73\n",
      "Train loss 0.07563849124643537\n",
      "Valid loss 0.09173859336546489\n",
      "previous_eval_loss 0.0910106748342514\n",
      "#################\n",
      "###Epoch: 74\n",
      "Train loss 0.07516635457674663\n",
      "Valid loss 0.09142601383583886\n",
      "previous_eval_loss 0.0910106748342514\n",
      "#################\n",
      "###Epoch: 75\n",
      "Train loss 0.07470138867696126\n",
      "Valid loss 0.09110305138996669\n",
      "previous_eval_loss 0.0910106748342514\n",
      "#################\n",
      "###Epoch: 76\n",
      "Train loss 0.07480537587845767\n",
      "Valid loss 0.09109792219741004\n",
      "previous_eval_loss 0.0910106748342514\n",
      "#################\n",
      "###Epoch: 77\n",
      "Train loss 0.07398241261641185\n",
      "Valid loss 0.08996519552809852\n",
      "previous_eval_loss 0.08996519552809852\n",
      "#################\n",
      "###Epoch: 78\n",
      "Train loss 0.07373656884387687\n",
      "Valid loss 0.09132974275520869\n",
      "previous_eval_loss 0.08996519552809852\n",
      "#################\n",
      "###Epoch: 79\n",
      "Train loss 0.07315259261263742\n",
      "Valid loss 0.09018193504640035\n",
      "previous_eval_loss 0.08996519552809852\n",
      "#################\n",
      "###Epoch: 80\n",
      "Train loss 0.07342431749458667\n",
      "Valid loss 0.0898400406752314\n",
      "previous_eval_loss 0.0898400406752314\n",
      "#################\n",
      "###Epoch: 81\n",
      "Train loss 0.07336427312758234\n",
      "Valid loss 0.08991906685488564\n",
      "previous_eval_loss 0.0898400406752314\n",
      "#################\n",
      "###Epoch: 82\n",
      "Train loss 0.07271549022859997\n",
      "Valid loss 0.08993865123816899\n",
      "previous_eval_loss 0.0898400406752314\n",
      "#################\n",
      "###Epoch: 83\n",
      "Train loss 0.07259983417612535\n",
      "Valid loss 0.0898815169930458\n",
      "previous_eval_loss 0.0898400406752314\n",
      "#################\n",
      "###Epoch: 84\n",
      "Train loss 0.07236875786825463\n",
      "Valid loss 0.09159756451845169\n",
      "previous_eval_loss 0.0898400406752314\n",
      "#################\n",
      "###Epoch: 85\n",
      "Train loss 0.07291881988445918\n",
      "Valid loss 0.09091742017439433\n",
      "previous_eval_loss 0.0898400406752314\n",
      "#################\n",
      "###Epoch: 86\n",
      "Train loss 0.07311010277933544\n",
      "Valid loss 0.08949109379734312\n",
      "previous_eval_loss 0.08949109379734312\n",
      "#################\n",
      "###Epoch: 87\n",
      "Train loss 0.07163428777345905\n",
      "Valid loss 0.08941922123943057\n",
      "previous_eval_loss 0.08941922123943057\n",
      "#################\n",
      "###Epoch: 88\n",
      "Train loss 0.07157641400893529\n",
      "Valid loss 0.0911208103810038\n",
      "previous_eval_loss 0.08941922123943057\n",
      "#################\n",
      "###Epoch: 89\n",
      "Train loss 0.07177620546685325\n",
      "Valid loss 0.08931523561477661\n",
      "previous_eval_loss 0.08931523561477661\n",
      "#################\n",
      "###Epoch: 90\n",
      "Train loss 0.07105584083883851\n",
      "Valid loss 0.09114504392657961\n",
      "previous_eval_loss 0.08931523561477661\n",
      "#################\n",
      "###Epoch: 91\n",
      "Train loss 0.07078208650151889\n",
      "Valid loss 0.0894024350813457\n",
      "previous_eval_loss 0.08931523561477661\n",
      "#################\n",
      "###Epoch: 92\n",
      "Train loss 0.06986436440988823\n",
      "Valid loss 0.08855809484209333\n",
      "previous_eval_loss 0.08855809484209333\n",
      "#################\n",
      "###Epoch: 93\n",
      "Train loss 0.06949629358671329\n",
      "Valid loss 0.08963148934500557\n",
      "previous_eval_loss 0.08855809484209333\n",
      "#################\n",
      "###Epoch: 94\n",
      "Train loss 0.07060300834752896\n",
      "Valid loss 0.08981297378029142\n",
      "previous_eval_loss 0.08855809484209333\n",
      "#################\n",
      "###Epoch: 95\n",
      "Train loss 0.07077926728460524\n",
      "Valid loss 0.089100681245327\n",
      "previous_eval_loss 0.08855809484209333\n",
      "#################\n",
      "###Epoch: 96\n",
      "Train loss 0.06936631710441024\n",
      "Valid loss 0.08890375282083239\n",
      "previous_eval_loss 0.08855809484209333\n",
      "#################\n",
      "###Epoch: 97\n",
      "Train loss 0.0686224486540865\n",
      "Valid loss 0.0877546604190554\n",
      "previous_eval_loss 0.0877546604190554\n",
      "#################\n",
      "###Epoch: 98\n",
      "Train loss 0.06854026336912755\n",
      "Valid loss 0.08743128499814443\n",
      "previous_eval_loss 0.08743128499814443\n",
      "#################\n",
      "###Epoch: 99\n",
      "Train loss 0.06792130679995925\n",
      "Valid loss 0.08794904074498586\n",
      "previous_eval_loss 0.08743128499814443\n",
      "#################\n",
      "###Epoch: 100\n",
      "Train loss 0.06781170158474534\n",
      "Valid loss 0.08847162340368543\n",
      "previous_eval_loss 0.08743128499814443\n",
      "#################\n",
      "###Epoch: 101\n",
      "Train loss 0.06820926097808061\n",
      "Valid loss 0.08794665655919484\n",
      "previous_eval_loss 0.08743128499814443\n",
      "#################\n",
      "###Epoch: 102\n",
      "Train loss 0.0687002852835037\n",
      "Valid loss 0.08782507159880229\n",
      "previous_eval_loss 0.08743128499814443\n",
      "#################\n",
      "###Epoch: 103\n",
      "Train loss 0.06819908017361606\n",
      "Valid loss 0.08842829934188298\n",
      "previous_eval_loss 0.08743128499814443\n",
      "#################\n",
      "###Epoch: 104\n",
      "Train loss 0.06772495709635594\n",
      "Valid loss 0.08785605217729296\n",
      "previous_eval_loss 0.08743128499814443\n",
      "#################\n",
      "###Epoch: 105\n",
      "Train loss 0.06774049955937597\n",
      "Valid loss 0.0892352962068149\n",
      "previous_eval_loss 0.08743128499814443\n",
      "#################\n",
      "###Epoch: 106\n",
      "Train loss 0.06709453201404324\n",
      "Valid loss 0.0875554723399026\n",
      "previous_eval_loss 0.08743128499814443\n",
      "#################\n",
      "###Epoch: 107\n",
      "Train loss 0.06764127369280215\n",
      "Valid loss 0.08777031408888954\n",
      "previous_eval_loss 0.08743128499814443\n",
      "#################\n",
      "###Epoch: 108\n",
      "Train loss 0.06765731010172102\n",
      "Valid loss 0.08718345633574895\n",
      "previous_eval_loss 0.08718345633574895\n",
      "#################\n",
      "###Epoch: 109\n",
      "Train loss 0.06855201955746722\n",
      "Valid loss 0.08925944886037282\n",
      "previous_eval_loss 0.08718345633574895\n",
      "#################\n",
      "###Epoch: 110\n",
      "Train loss 0.06821322068572044\n",
      "Valid loss 0.0883779621550015\n",
      "previous_eval_loss 0.08718345633574895\n",
      "#################\n",
      "###Epoch: 111\n",
      "Train loss 0.06707279646286259\n",
      "Valid loss 0.08792470395565033\n",
      "previous_eval_loss 0.08718345633574895\n",
      "#################\n",
      "###Epoch: 112\n",
      "Train loss 0.06643320689046825\n",
      "Valid loss 0.08660874835082463\n",
      "previous_eval_loss 0.08660874835082463\n",
      "#################\n",
      "###Epoch: 113\n",
      "Train loss 0.0661443357390386\n",
      "Valid loss 0.0872959601027625\n",
      "previous_eval_loss 0.08660874835082463\n",
      "#################\n",
      "###Epoch: 114\n",
      "Train loss 0.06684847369238182\n",
      "Valid loss 0.0869448014668056\n",
      "previous_eval_loss 0.08660874835082463\n",
      "#################\n",
      "###Epoch: 115\n",
      "Train loss 0.06648497021308651\n",
      "Valid loss 0.08726182792867933\n",
      "previous_eval_loss 0.08660874835082463\n",
      "#################\n",
      "###Epoch: 116\n",
      "Train loss 0.06560489135207953\n",
      "Valid loss 0.08683412096330098\n",
      "previous_eval_loss 0.08660874835082463\n",
      "#################\n",
      "###Epoch: 117\n",
      "Train loss 0.06501441352345326\n",
      "Valid loss 0.08669165415423256\n",
      "previous_eval_loss 0.08660874835082463\n",
      "#################\n",
      "###Epoch: 118\n",
      "Train loss 0.06535289836702524\n",
      "Valid loss 0.08706751252923693\n",
      "previous_eval_loss 0.08660874835082463\n",
      "#################\n",
      "###Epoch: 119\n",
      "Train loss 0.06519262189114536\n",
      "Valid loss 0.08617001452616282\n",
      "previous_eval_loss 0.08617001452616282\n",
      "#################\n",
      "###Epoch: 120\n",
      "Train loss 0.06500519080846398\n",
      "Valid loss 0.08671074679919652\n",
      "previous_eval_loss 0.08617001452616282\n",
      "#################\n",
      "###Epoch: 121\n",
      "Train loss 0.06579941042043545\n",
      "Valid loss 0.08703139956508364\n",
      "previous_eval_loss 0.08617001452616282\n",
      "#################\n",
      "###Epoch: 122\n",
      "Train loss 0.06682085342429302\n",
      "Valid loss 0.08642855073724474\n",
      "previous_eval_loss 0.08617001452616282\n",
      "#################\n",
      "###Epoch: 123\n",
      "Train loss 0.06542350062065655\n",
      "Valid loss 0.0866620849285807\n",
      "previous_eval_loss 0.08617001452616282\n",
      "#################\n",
      "###Epoch: 124\n",
      "Train loss 0.06433062821074768\n",
      "Valid loss 0.08690958789416722\n",
      "previous_eval_loss 0.08617001452616282\n",
      "#################\n",
      "###Epoch: 125\n",
      "Train loss 0.06401978515916401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss 0.08713833774839129\n",
      "previous_eval_loss 0.08617001452616282\n",
      "#################\n",
      "###Epoch: 126\n",
      "Train loss 0.06412568371053096\n",
      "Valid loss 0.08728707156011037\n",
      "previous_eval_loss 0.08617001452616282\n",
      "#################\n",
      "###Epoch: 127\n",
      "Train loss 0.06444660546603026\n",
      "Valid loss 0.08640284623418536\n",
      "previous_eval_loss 0.08617001452616282\n",
      "#################\n",
      "###Epoch: 128\n",
      "Train loss 0.06423243080024366\n",
      "Valid loss 0.08686772946800504\n",
      "previous_eval_loss 0.08617001452616282\n",
      "#################\n",
      "###Epoch: 129\n",
      "Train loss 0.06490520898390699\n",
      "Valid loss 0.086388641170093\n",
      "previous_eval_loss 0.08617001452616282\n",
      "early stop the model at Epoch:  129\n",
      "#################\n",
      "###Epoch: 0\n",
      "Train loss 0.2941984396289896\n",
      "Valid loss 0.19649753826005117\n",
      "#################\n",
      "###Epoch: 1\n",
      "Train loss 0.22018871980684776\n",
      "Valid loss 0.17895579125199998\n",
      "previous_eval_loss 0.17895579125199998\n",
      "#################\n",
      "###Epoch: 2\n",
      "Train loss 0.1994883120059967\n",
      "Valid loss 0.1662836628300803\n",
      "previous_eval_loss 0.1662836628300803\n",
      "#################\n",
      "###Epoch: 3\n",
      "Train loss 0.18615289529164633\n",
      "Valid loss 0.15956873978887284\n",
      "previous_eval_loss 0.15956873978887284\n",
      "#################\n",
      "###Epoch: 4\n",
      "Train loss 0.17711916786653023\n",
      "Valid loss 0.15420792145388468\n",
      "previous_eval_loss 0.15420792145388468\n",
      "#################\n",
      "###Epoch: 5\n",
      "Train loss 0.168633371591568\n",
      "Valid loss 0.15059998631477356\n",
      "previous_eval_loss 0.15059998631477356\n",
      "#################\n",
      "###Epoch: 6\n",
      "Train loss 0.1614049380576169\n",
      "Valid loss 0.14627316381250108\n",
      "previous_eval_loss 0.14627316381250108\n",
      "#################\n",
      "###Epoch: 7\n",
      "Train loss 0.15462036927541098\n",
      "Valid loss 0.14477028804165976\n",
      "previous_eval_loss 0.14477028804165976\n",
      "#################\n",
      "###Epoch: 8\n",
      "Train loss 0.15075980126857758\n",
      "Valid loss 0.13958941187177384\n",
      "previous_eval_loss 0.13958941187177384\n",
      "#################\n",
      "###Epoch: 9\n",
      "Train loss 0.1444036121721621\n",
      "Valid loss 0.1345087523971285\n",
      "previous_eval_loss 0.1345087523971285\n",
      "#################\n",
      "###Epoch: 10\n",
      "Train loss 0.13979874164969833\n",
      "Valid loss 0.1314490990979331\n",
      "previous_eval_loss 0.1314490990979331\n",
      "#################\n",
      "###Epoch: 11\n",
      "Train loss 0.1351994883131098\n",
      "Valid loss 0.12821231569562638\n",
      "previous_eval_loss 0.12821231569562638\n",
      "#################\n",
      "###Epoch: 12\n",
      "Train loss 0.1313866937050113\n",
      "Valid loss 0.12497785687446594\n",
      "previous_eval_loss 0.12497785687446594\n",
      "#################\n",
      "###Epoch: 13\n",
      "Train loss 0.13127723087867102\n",
      "Valid loss 0.1241503113082477\n",
      "previous_eval_loss 0.1241503113082477\n",
      "#################\n",
      "###Epoch: 14\n",
      "Train loss 0.1275910398474446\n",
      "Valid loss 0.12174407712050847\n",
      "previous_eval_loss 0.12174407712050847\n",
      "#################\n",
      "###Epoch: 15\n",
      "Train loss 0.12536365649214498\n",
      "Valid loss 0.12276537929262434\n",
      "previous_eval_loss 0.12174407712050847\n",
      "#################\n",
      "###Epoch: 16\n",
      "Train loss 0.12513935538353743\n",
      "Valid loss 0.11975792050361633\n",
      "previous_eval_loss 0.11975792050361633\n",
      "#################\n",
      "###Epoch: 17\n",
      "Train loss 0.12303044674573121\n",
      "Valid loss 0.11703004688024521\n",
      "previous_eval_loss 0.11703004688024521\n",
      "#################\n",
      "###Epoch: 18\n",
      "Train loss 0.12173569395586296\n",
      "Valid loss 0.12244596545185361\n",
      "previous_eval_loss 0.11703004688024521\n",
      "#################\n",
      "###Epoch: 19\n",
      "Train loss 0.12073748724328147\n",
      "Valid loss 0.11553237161466054\n",
      "previous_eval_loss 0.11553237161466054\n",
      "#################\n",
      "###Epoch: 20\n",
      "Train loss 0.11837957164755573\n",
      "Valid loss 0.11325921756880623\n",
      "previous_eval_loss 0.11325921756880623\n",
      "#################\n",
      "###Epoch: 21\n",
      "Train loss 0.11629149566094081\n",
      "Valid loss 0.11411659100225993\n",
      "previous_eval_loss 0.11325921756880623\n",
      "#################\n",
      "###Epoch: 22\n",
      "Train loss 0.11518530437239895\n",
      "Valid loss 0.11202360157455717\n",
      "previous_eval_loss 0.11202360157455717\n",
      "#################\n",
      "###Epoch: 23\n",
      "Train loss 0.11392314759669481\n",
      "Valid loss 0.1104355975985527\n",
      "previous_eval_loss 0.1104355975985527\n",
      "#################\n",
      "###Epoch: 24\n",
      "Train loss 0.11193785871620532\n",
      "Valid loss 0.10856471849339348\n",
      "previous_eval_loss 0.10856471849339348\n",
      "#################\n",
      "###Epoch: 25\n",
      "Train loss 0.1105950814154413\n",
      "Valid loss 0.10772735412631716\n",
      "previous_eval_loss 0.10772735412631716\n",
      "#################\n",
      "###Epoch: 26\n",
      "Train loss 0.10913900699880388\n",
      "Valid loss 0.10628313890525273\n",
      "previous_eval_loss 0.10628313890525273\n",
      "#################\n",
      "###Epoch: 27\n",
      "Train loss 0.10795749613532314\n",
      "Valid loss 0.10829351097345352\n",
      "previous_eval_loss 0.10628313890525273\n",
      "#################\n",
      "###Epoch: 28\n",
      "Train loss 0.10680509413833972\n",
      "Valid loss 0.10492436162063054\n",
      "previous_eval_loss 0.10492436162063054\n",
      "#################\n",
      "###Epoch: 29\n",
      "Train loss 0.10600468792297223\n",
      "Valid loss 0.10383138699190957\n",
      "previous_eval_loss 0.10383138699190957\n",
      "#################\n",
      "###Epoch: 30\n",
      "Train loss 0.1058145750451971\n",
      "Valid loss 0.1047477275133133\n",
      "previous_eval_loss 0.10383138699190957\n",
      "#################\n",
      "###Epoch: 31\n",
      "Train loss 0.10455522686243057\n",
      "Valid loss 0.10343528326068606\n",
      "previous_eval_loss 0.10343528326068606\n",
      "#################\n",
      "###Epoch: 32\n",
      "Train loss 0.10265860899730965\n",
      "Valid loss 0.10222616046667099\n",
      "previous_eval_loss 0.10222616046667099\n",
      "#################\n",
      "###Epoch: 33\n",
      "Train loss 0.10185910982114298\n",
      "Valid loss 0.10187362240893501\n",
      "previous_eval_loss 0.10187362240893501\n",
      "#################\n",
      "###Epoch: 34\n",
      "Train loss 0.10105053859728354\n",
      "Valid loss 0.1004030608705112\n",
      "previous_eval_loss 0.1004030608705112\n",
      "#################\n",
      "###Epoch: 35\n",
      "Train loss 0.09846483364149376\n",
      "Valid loss 0.10034957953861781\n",
      "previous_eval_loss 0.10034957953861781\n",
      "#################\n",
      "###Epoch: 36\n",
      "Train loss 0.0990689785944091\n",
      "Valid loss 0.10092094221285411\n",
      "previous_eval_loss 0.10034957953861781\n",
      "#################\n",
      "###Epoch: 37\n",
      "Train loss 0.09957436527366992\n",
      "Valid loss 0.09888281673192978\n",
      "previous_eval_loss 0.09888281673192978\n",
      "#################\n",
      "###Epoch: 38\n",
      "Train loss 0.09744419709399894\n",
      "Valid loss 0.09818126793418612\n",
      "previous_eval_loss 0.09818126793418612\n",
      "#################\n",
      "###Epoch: 39\n",
      "Train loss 0.09579818005915042\n",
      "Valid loss 0.09720443508454732\n",
      "previous_eval_loss 0.09720443508454732\n",
      "#################\n",
      "###Epoch: 40\n",
      "Train loss 0.09543802589178085\n",
      "Valid loss 0.09631543606519699\n",
      "previous_eval_loss 0.09631543606519699\n",
      "#################\n",
      "###Epoch: 41\n",
      "Train loss 0.09355795162695425\n",
      "Valid loss 0.09663063713482448\n",
      "previous_eval_loss 0.09631543606519699\n",
      "#################\n",
      "###Epoch: 42\n",
      "Train loss 0.09292830250881336\n",
      "Valid loss 0.09618416428565979\n",
      "previous_eval_loss 0.09618416428565979\n",
      "#################\n",
      "###Epoch: 43\n",
      "Train loss 0.09203471933250074\n",
      "Valid loss 0.09533471188374928\n",
      "previous_eval_loss 0.09533471188374928\n",
      "#################\n",
      "###Epoch: 44\n",
      "Train loss 0.09182465849099336\n",
      "Valid loss 0.09627806288855416\n",
      "previous_eval_loss 0.09533471188374928\n",
      "#################\n",
      "###Epoch: 45\n",
      "Train loss 0.091726907701404\n",
      "Valid loss 0.0940107884151595\n",
      "previous_eval_loss 0.0940107884151595\n",
      "#################\n",
      "###Epoch: 46\n",
      "Train loss 0.08979563746187422\n",
      "Valid loss 0.09363469800778798\n",
      "previous_eval_loss 0.09363469800778798\n",
      "#################\n",
      "###Epoch: 47\n",
      "Train loss 0.09124681105216344\n",
      "Valid loss 0.0960659310221672\n",
      "previous_eval_loss 0.09363469800778798\n",
      "#################\n",
      "###Epoch: 48\n",
      "Train loss 0.0886256898994799\n",
      "Valid loss 0.09380529288734708\n",
      "previous_eval_loss 0.09363469800778798\n",
      "#################\n",
      "###Epoch: 49\n",
      "Train loss 0.08744886186387804\n",
      "Valid loss 0.09176992305687495\n",
      "previous_eval_loss 0.09176992305687495\n",
      "#################\n",
      "###Epoch: 50\n",
      "Train loss 0.08740500857432683\n",
      "Valid loss 0.09266845562628337\n",
      "previous_eval_loss 0.09176992305687495\n",
      "#################\n",
      "###Epoch: 51\n",
      "Train loss 0.08704563975334167\n",
      "Valid loss 0.09591394769293922\n",
      "previous_eval_loss 0.09176992305687495\n",
      "#################\n",
      "###Epoch: 52\n",
      "Train loss 0.0881190065432478\n",
      "Valid loss 0.09195144368069512\n",
      "previous_eval_loss 0.09176992305687495\n",
      "#################\n",
      "###Epoch: 53\n",
      "Train loss 0.08678564567256856\n",
      "Valid loss 0.09112246653863362\n",
      "previous_eval_loss 0.09112246653863362\n",
      "#################\n",
      "###Epoch: 54\n",
      "Train loss 0.08635118824464304\n",
      "Valid loss 0.09353232170854296\n",
      "previous_eval_loss 0.09112246653863362\n",
      "#################\n",
      "###Epoch: 55\n",
      "Train loss 0.08530746897061665\n",
      "Valid loss 0.09090584942272731\n",
      "previous_eval_loss 0.09090584942272731\n",
      "#################\n",
      "###Epoch: 56\n",
      "Train loss 0.08312501675552791\n",
      "Valid loss 0.09052938435758863\n",
      "previous_eval_loss 0.09052938435758863\n",
      "#################\n",
      "###Epoch: 57\n",
      "Train loss 0.08250529208668957\n",
      "Valid loss 0.09065386120762144\n",
      "previous_eval_loss 0.09052938435758863\n",
      "#################\n",
      "###Epoch: 58\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.08320132808552848\n",
      "Valid loss 0.0901557377406529\n",
      "previous_eval_loss 0.0901557377406529\n",
      "#################\n",
      "###Epoch: 59\n",
      "Train loss 0.08156494575518149\n",
      "Valid loss 0.08857837638684682\n",
      "previous_eval_loss 0.08857837638684682\n",
      "#################\n",
      "###Epoch: 60\n",
      "Train loss 0.08127771179985117\n",
      "Valid loss 0.08971371927431651\n",
      "previous_eval_loss 0.08857837638684682\n",
      "#################\n",
      "###Epoch: 61\n",
      "Train loss 0.0811072748016428\n",
      "Valid loss 0.09026871940919332\n",
      "previous_eval_loss 0.08857837638684682\n",
      "#################\n",
      "###Epoch: 62\n",
      "Train loss 0.08063171693572292\n",
      "Valid loss 0.08902498973267418\n",
      "previous_eval_loss 0.08857837638684682\n",
      "#################\n",
      "###Epoch: 63\n",
      "Train loss 0.0816981323339321\n",
      "Valid loss 0.08969327062368393\n",
      "previous_eval_loss 0.08857837638684682\n",
      "#################\n",
      "###Epoch: 64\n",
      "Train loss 0.08045275509357452\n",
      "Valid loss 0.08882168361118861\n",
      "previous_eval_loss 0.08857837638684682\n",
      "#################\n",
      "###Epoch: 65\n",
      "Train loss 0.07947513764655148\n",
      "Valid loss 0.0882773186479296\n",
      "previous_eval_loss 0.0882773186479296\n",
      "#################\n",
      "###Epoch: 66\n",
      "Train loss 0.08007594584314912\n",
      "Valid loss 0.0893409645983151\n",
      "previous_eval_loss 0.0882773186479296\n",
      "#################\n",
      "###Epoch: 67\n",
      "Train loss 0.07938626988066567\n",
      "Valid loss 0.08883626226867948\n",
      "previous_eval_loss 0.0882773186479296\n",
      "#################\n",
      "###Epoch: 68\n",
      "Train loss 0.0781866176812737\n",
      "Valid loss 0.08808756193944386\n",
      "previous_eval_loss 0.08808756193944386\n",
      "#################\n",
      "###Epoch: 69\n",
      "Train loss 0.07668714142507976\n",
      "Valid loss 0.08730839086430413\n",
      "previous_eval_loss 0.08730839086430413\n",
      "#################\n",
      "###Epoch: 70\n",
      "Train loss 0.07618300589146437\n",
      "Valid loss 0.08775319797652108\n",
      "previous_eval_loss 0.08730839086430413\n",
      "#################\n",
      "###Epoch: 71\n",
      "Train loss 0.07717975504972317\n",
      "Valid loss 0.08720213281256813\n",
      "previous_eval_loss 0.08720213281256813\n",
      "#################\n",
      "###Epoch: 72\n",
      "Train loss 0.07623556752999623\n",
      "Valid loss 0.08711439158235278\n",
      "previous_eval_loss 0.08711439158235278\n",
      "#################\n",
      "###Epoch: 73\n",
      "Train loss 0.07652025117918297\n",
      "Valid loss 0.08733577706984111\n",
      "previous_eval_loss 0.08711439158235278\n",
      "#################\n",
      "###Epoch: 74\n",
      "Train loss 0.07503800908172573\n",
      "Valid loss 0.08757548247064863\n",
      "previous_eval_loss 0.08711439158235278\n",
      "#################\n",
      "###Epoch: 75\n",
      "Train loss 0.07547495320991233\n",
      "Valid loss 0.08641691080161504\n",
      "previous_eval_loss 0.08641691080161504\n",
      "#################\n",
      "###Epoch: 76\n",
      "Train loss 0.07420958413018121\n",
      "Valid loss 0.08590201607772283\n",
      "previous_eval_loss 0.08590201607772283\n",
      "#################\n",
      "###Epoch: 77\n",
      "Train loss 0.07522353723093315\n",
      "Valid loss 0.08613473709140505\n",
      "previous_eval_loss 0.08590201607772283\n",
      "#################\n",
      "###Epoch: 78\n",
      "Train loss 0.07466143093727252\n",
      "Valid loss 0.08691414871386119\n",
      "previous_eval_loss 0.08590201607772283\n",
      "#################\n",
      "###Epoch: 79\n",
      "Train loss 0.07365579709962562\n",
      "Valid loss 0.08626827491181237\n",
      "previous_eval_loss 0.08590201607772283\n",
      "#################\n",
      "###Epoch: 80\n",
      "Train loss 0.07312926925994732\n",
      "Valid loss 0.08601399830409459\n",
      "previous_eval_loss 0.08590201607772283\n",
      "#################\n",
      "###Epoch: 81\n",
      "Train loss 0.07371003373905465\n",
      "Valid loss 0.0855567040187972\n",
      "previous_eval_loss 0.0855567040187972\n",
      "#################\n",
      "###Epoch: 82\n",
      "Train loss 0.07264924187351156\n",
      "Valid loss 0.08568836748600006\n",
      "previous_eval_loss 0.0855567040187972\n",
      "#################\n",
      "###Epoch: 83\n",
      "Train loss 0.07268322811082557\n",
      "Valid loss 0.08507669291325978\n",
      "previous_eval_loss 0.08507669291325978\n",
      "#################\n",
      "###Epoch: 84\n",
      "Train loss 0.0721220058147554\n",
      "Valid loss 0.08513420607362475\n",
      "previous_eval_loss 0.08507669291325978\n",
      "#################\n",
      "###Epoch: 85\n",
      "Train loss 0.07182328099453891\n",
      "Valid loss 0.08544140947716576\n",
      "previous_eval_loss 0.08507669291325978\n",
      "#################\n",
      "###Epoch: 86\n",
      "Train loss 0.07186058798321972\n",
      "Valid loss 0.08455587817089898\n",
      "previous_eval_loss 0.08455587817089898\n",
      "#################\n",
      "###Epoch: 87\n",
      "Train loss 0.07101213725076781\n",
      "Valid loss 0.08505580787147794\n",
      "previous_eval_loss 0.08455587817089898\n",
      "#################\n",
      "###Epoch: 88\n",
      "Train loss 0.07121035787794325\n",
      "Valid loss 0.08548553181546074\n",
      "previous_eval_loss 0.08455587817089898\n",
      "#################\n",
      "###Epoch: 89\n",
      "Train loss 0.07053950249596878\n",
      "Valid loss 0.08414461783000401\n",
      "previous_eval_loss 0.08414461783000401\n",
      "#################\n",
      "###Epoch: 90\n",
      "Train loss 0.07068503896395366\n",
      "Valid loss 0.08426620385476521\n",
      "previous_eval_loss 0.08414461783000401\n",
      "#################\n",
      "###Epoch: 91\n",
      "Train loss 0.07052063362465964\n",
      "Valid loss 0.08435740747622081\n",
      "previous_eval_loss 0.08414461783000401\n",
      "#################\n",
      "###Epoch: 92\n",
      "Train loss 0.06968102755921858\n",
      "Valid loss 0.08449477702379227\n",
      "previous_eval_loss 0.08414461783000401\n",
      "#################\n",
      "###Epoch: 93\n",
      "Train loss 0.07027695879892067\n",
      "Valid loss 0.08464274555444717\n",
      "previous_eval_loss 0.08414461783000401\n",
      "#################\n",
      "###Epoch: 94\n",
      "Train loss 0.06973301122585933\n",
      "Valid loss 0.08398073485919408\n",
      "previous_eval_loss 0.08398073485919408\n",
      "#################\n",
      "###Epoch: 95\n",
      "Train loss 0.06925966770008758\n",
      "Valid loss 0.08507424273661204\n",
      "previous_eval_loss 0.08398073485919408\n",
      "#################\n",
      "###Epoch: 96\n",
      "Train loss 0.06958409095252002\n",
      "Valid loss 0.08422749489545822\n",
      "previous_eval_loss 0.08398073485919408\n",
      "#################\n",
      "###Epoch: 97\n",
      "Train loss 0.06975364919613909\n",
      "Valid loss 0.0851353013089725\n",
      "previous_eval_loss 0.08398073485919408\n",
      "#################\n",
      "###Epoch: 98\n",
      "Train loss 0.06920808388127221\n",
      "Valid loss 0.0845557547041348\n",
      "previous_eval_loss 0.08398073485919408\n",
      "#################\n",
      "###Epoch: 99\n",
      "Train loss 0.06872476223442289\n",
      "Valid loss 0.08544043345110756\n",
      "previous_eval_loss 0.08398073485919408\n",
      "#################\n",
      "###Epoch: 100\n",
      "Train loss 0.06860628158405975\n",
      "Valid loss 0.08471314183303288\n",
      "previous_eval_loss 0.08398073485919408\n",
      "#################\n",
      "###Epoch: 101\n",
      "Train loss 0.06872692759390231\n",
      "Valid loss 0.08427221647330693\n",
      "previous_eval_loss 0.08398073485919408\n",
      "#################\n",
      "###Epoch: 102\n",
      "Train loss 0.06820694536522583\n",
      "Valid loss 0.08424201288393565\n",
      "previous_eval_loss 0.08398073485919408\n",
      "#################\n",
      "###Epoch: 103\n",
      "Train loss 0.06811772148918223\n",
      "Valid loss 0.08410113943474633\n",
      "previous_eval_loss 0.08398073485919408\n",
      "#################\n",
      "###Epoch: 104\n",
      "Train loss 0.06764350707332294\n",
      "Valid loss 0.08456700933831078\n",
      "previous_eval_loss 0.08398073485919408\n",
      "early stop the model at Epoch:  104\n",
      "#################\n",
      "###Epoch: 0\n",
      "Train loss 0.302616110002553\n",
      "Valid loss 0.1926972929920469\n",
      "#################\n",
      "###Epoch: 1\n",
      "Train loss 0.21848579192603076\n",
      "Valid loss 0.17461663484573364\n",
      "previous_eval_loss 0.17461663484573364\n",
      "#################\n",
      "###Epoch: 2\n",
      "Train loss 0.19808957201463204\n",
      "Valid loss 0.16355960922581808\n",
      "previous_eval_loss 0.16355960922581808\n",
      "#################\n",
      "###Epoch: 3\n",
      "Train loss 0.18079729433412906\n",
      "Valid loss 0.1544414609670639\n",
      "previous_eval_loss 0.1544414609670639\n",
      "#################\n",
      "###Epoch: 4\n",
      "Train loss 0.1692271011847037\n",
      "Valid loss 0.14860139787197113\n",
      "previous_eval_loss 0.14860139787197113\n",
      "#################\n",
      "###Epoch: 5\n",
      "Train loss 0.16156039911287803\n",
      "Valid loss 0.1430108504635947\n",
      "previous_eval_loss 0.1430108504635947\n",
      "#################\n",
      "###Epoch: 6\n",
      "Train loss 0.15436733376096795\n",
      "Valid loss 0.1384428803409849\n",
      "previous_eval_loss 0.1384428803409849\n",
      "#################\n",
      "###Epoch: 7\n",
      "Train loss 0.14875548277740125\n",
      "Valid loss 0.1352532250540597\n",
      "previous_eval_loss 0.1352532250540597\n",
      "#################\n",
      "###Epoch: 8\n",
      "Train loss 0.14449221226904127\n",
      "Valid loss 0.13068654707499913\n",
      "previous_eval_loss 0.13068654707499913\n",
      "#################\n",
      "###Epoch: 9\n",
      "Train loss 0.14351386797648888\n",
      "Valid loss 0.1279229415314538\n",
      "previous_eval_loss 0.1279229415314538\n",
      "#################\n",
      "###Epoch: 10\n",
      "Train loss 0.1397615933307895\n",
      "Valid loss 0.1270097675068038\n",
      "previous_eval_loss 0.1270097675068038\n",
      "#################\n",
      "###Epoch: 11\n",
      "Train loss 0.13764262089022883\n",
      "Valid loss 0.1242072337440082\n",
      "previous_eval_loss 0.1242072337440082\n",
      "#################\n",
      "###Epoch: 12\n",
      "Train loss 0.13270119356888313\n",
      "Valid loss 0.12244247219392232\n",
      "previous_eval_loss 0.12244247219392232\n",
      "#################\n",
      "###Epoch: 13\n",
      "Train loss 0.1298697723282708\n",
      "Valid loss 0.12504964108977998\n",
      "previous_eval_loss 0.12244247219392232\n",
      "#################\n",
      "###Epoch: 14\n",
      "Train loss 0.12802891791970641\n",
      "Valid loss 0.11959900813443321\n",
      "previous_eval_loss 0.11959900813443321\n",
      "#################\n",
      "###Epoch: 15\n",
      "Train loss 0.12513888930832898\n",
      "Valid loss 0.11580899144921984\n",
      "previous_eval_loss 0.11580899144921984\n",
      "#################\n",
      "###Epoch: 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.1235269973123515\n",
      "Valid loss 0.11558129851307188\n",
      "previous_eval_loss 0.11558129851307188\n",
      "#################\n",
      "###Epoch: 17\n",
      "Train loss 0.12201060741036027\n",
      "Valid loss 0.1130071569766317\n",
      "previous_eval_loss 0.1130071569766317\n",
      "#################\n",
      "###Epoch: 18\n",
      "Train loss 0.12127257193680163\n",
      "Valid loss 0.11187517642974854\n",
      "previous_eval_loss 0.11187517642974854\n",
      "#################\n",
      "###Epoch: 19\n",
      "Train loss 0.11944886490150734\n",
      "Valid loss 0.1123554642711367\n",
      "previous_eval_loss 0.11187517642974854\n",
      "#################\n",
      "###Epoch: 20\n",
      "Train loss 0.11817071338494618\n",
      "Valid loss 0.1111358180642128\n",
      "previous_eval_loss 0.1111358180642128\n",
      "#################\n",
      "###Epoch: 21\n",
      "Train loss 0.11639671883097401\n",
      "Valid loss 0.10690443643501826\n",
      "previous_eval_loss 0.10690443643501826\n",
      "#################\n",
      "###Epoch: 22\n",
      "Train loss 0.11499092589925837\n",
      "Valid loss 0.1070186857666288\n",
      "previous_eval_loss 0.10690443643501826\n",
      "#################\n",
      "###Epoch: 23\n",
      "Train loss 0.11356512622700797\n",
      "Valid loss 0.10570039706570762\n",
      "previous_eval_loss 0.10570039706570762\n",
      "#################\n",
      "###Epoch: 24\n",
      "Train loss 0.1120241532723109\n",
      "Valid loss 0.10501096291201455\n",
      "previous_eval_loss 0.10501096291201455\n",
      "#################\n",
      "###Epoch: 25\n",
      "Train loss 0.11143978133245751\n",
      "Valid loss 0.10347372825656619\n",
      "previous_eval_loss 0.10347372825656619\n",
      "#################\n",
      "###Epoch: 26\n",
      "Train loss 0.10992601403483639\n",
      "Valid loss 0.10442042989390236\n",
      "previous_eval_loss 0.10347372825656619\n",
      "#################\n",
      "###Epoch: 27\n",
      "Train loss 0.10965476019514932\n",
      "Valid loss 0.1026410066655704\n",
      "previous_eval_loss 0.1026410066655704\n",
      "#################\n",
      "###Epoch: 28\n",
      "Train loss 0.1077216096498348\n",
      "Valid loss 0.1025400874870164\n",
      "previous_eval_loss 0.1025400874870164\n",
      "#################\n",
      "###Epoch: 29\n",
      "Train loss 0.10753357134483478\n",
      "Valid loss 0.10222956325326647\n",
      "previous_eval_loss 0.10222956325326647\n",
      "#################\n",
      "###Epoch: 30\n",
      "Train loss 0.10683451289380039\n",
      "Valid loss 0.09974481484719686\n",
      "previous_eval_loss 0.09974481484719686\n",
      "#################\n",
      "###Epoch: 31\n",
      "Train loss 0.10493662815403056\n",
      "Valid loss 0.09838753938674927\n",
      "previous_eval_loss 0.09838753938674927\n",
      "#################\n",
      "###Epoch: 32\n",
      "Train loss 0.10346017943488227\n",
      "Valid loss 0.09786582844597953\n",
      "previous_eval_loss 0.09786582844597953\n",
      "#################\n",
      "###Epoch: 33\n",
      "Train loss 0.10224717607100804\n",
      "Valid loss 0.09697279653378896\n",
      "previous_eval_loss 0.09697279653378896\n",
      "#################\n",
      "###Epoch: 34\n",
      "Train loss 0.10100238135567417\n",
      "Valid loss 0.09793394271816526\n",
      "previous_eval_loss 0.09697279653378896\n",
      "#################\n",
      "###Epoch: 35\n",
      "Train loss 0.10020305961370468\n",
      "Valid loss 0.09770616463252477\n",
      "previous_eval_loss 0.09697279653378896\n",
      "#################\n",
      "###Epoch: 36\n",
      "Train loss 0.09976353137581437\n",
      "Valid loss 0.09637775485004697\n",
      "previous_eval_loss 0.09637775485004697\n",
      "#################\n",
      "###Epoch: 37\n",
      "Train loss 0.09813423234003561\n",
      "Valid loss 0.09454808277743203\n",
      "previous_eval_loss 0.09454808277743203\n",
      "#################\n",
      "###Epoch: 38\n",
      "Train loss 0.09826896339654922\n",
      "Valid loss 0.09500314401728767\n",
      "previous_eval_loss 0.09454808277743203\n",
      "#################\n",
      "###Epoch: 39\n",
      "Train loss 0.09832401408089532\n",
      "Valid loss 0.09451006033590861\n",
      "previous_eval_loss 0.09451006033590861\n",
      "#################\n",
      "###Epoch: 40\n",
      "Train loss 0.09769183093750919\n",
      "Valid loss 0.09814506236995969\n",
      "previous_eval_loss 0.09451006033590861\n",
      "#################\n",
      "###Epoch: 41\n",
      "Train loss 0.09579340561672493\n",
      "Valid loss 0.09403999362673078\n",
      "previous_eval_loss 0.09403999362673078\n",
      "#################\n",
      "###Epoch: 42\n",
      "Train loss 0.09450212534930971\n",
      "Valid loss 0.09269325009414128\n",
      "previous_eval_loss 0.09269325009414128\n",
      "#################\n",
      "###Epoch: 43\n",
      "Train loss 0.09493879973888397\n",
      "Valid loss 0.09311823546886444\n",
      "previous_eval_loss 0.09269325009414128\n",
      "#################\n",
      "###Epoch: 44\n",
      "Train loss 0.09277553387262204\n",
      "Valid loss 0.09184568268912179\n",
      "previous_eval_loss 0.09184568268912179\n",
      "#################\n",
      "###Epoch: 45\n",
      "Train loss 0.09284121294816335\n",
      "Valid loss 0.0926895524774279\n",
      "previous_eval_loss 0.09184568268912179\n",
      "#################\n",
      "###Epoch: 46\n",
      "Train loss 0.09201071604534432\n",
      "Valid loss 0.09028331509658269\n",
      "previous_eval_loss 0.09028331509658269\n",
      "#################\n",
      "###Epoch: 47\n",
      "Train loss 0.09079778994675036\n",
      "Valid loss 0.09059875032731465\n",
      "previous_eval_loss 0.09028331509658269\n",
      "#################\n",
      "###Epoch: 48\n",
      "Train loss 0.09002719929924717\n",
      "Valid loss 0.09069749606507164\n",
      "previous_eval_loss 0.09028331509658269\n",
      "#################\n",
      "###Epoch: 49\n",
      "Train loss 0.08910592479838265\n",
      "Valid loss 0.0916578226855823\n",
      "previous_eval_loss 0.09028331509658269\n",
      "#################\n",
      "###Epoch: 50\n",
      "Train loss 0.08982699612776439\n",
      "Valid loss 0.08972487917968205\n",
      "previous_eval_loss 0.08972487917968205\n",
      "#################\n",
      "###Epoch: 51\n",
      "Train loss 0.08859840228601738\n",
      "Valid loss 0.08873337400811059\n",
      "previous_eval_loss 0.08873337400811059\n",
      "#################\n",
      "###Epoch: 52\n",
      "Train loss 0.08883618673792591\n",
      "Valid loss 0.08943064936569758\n",
      "previous_eval_loss 0.08873337400811059\n",
      "#################\n",
      "###Epoch: 53\n",
      "Train loss 0.08773774681267915\n",
      "Valid loss 0.08947483343737465\n",
      "previous_eval_loss 0.08873337400811059\n",
      "#################\n",
      "###Epoch: 54\n",
      "Train loss 0.08762309203545253\n",
      "Valid loss 0.08857460107122149\n",
      "previous_eval_loss 0.08857460107122149\n",
      "#################\n",
      "###Epoch: 55\n",
      "Train loss 0.086382907849771\n",
      "Valid loss 0.08767491791929517\n",
      "previous_eval_loss 0.08767491791929517\n",
      "#################\n",
      "###Epoch: 56\n",
      "Train loss 0.08459467854764727\n",
      "Valid loss 0.0871761611529759\n",
      "previous_eval_loss 0.0871761611529759\n",
      "#################\n",
      "###Epoch: 57\n",
      "Train loss 0.0847423799611904\n",
      "Valid loss 0.08713272639683314\n",
      "previous_eval_loss 0.08713272639683314\n",
      "#################\n",
      "###Epoch: 58\n",
      "Train loss 0.08415485780548167\n",
      "Valid loss 0.08651189825364522\n",
      "previous_eval_loss 0.08651189825364522\n",
      "#################\n",
      "###Epoch: 59\n",
      "Train loss 0.08487419039011002\n",
      "Valid loss 0.08604762170995985\n",
      "previous_eval_loss 0.08604762170995985\n",
      "#################\n",
      "###Epoch: 60\n",
      "Train loss 0.0833784970972273\n",
      "Valid loss 0.08594104434762682\n",
      "previous_eval_loss 0.08594104434762682\n",
      "#################\n",
      "###Epoch: 61\n",
      "Train loss 0.08354948323082041\n",
      "Valid loss 0.08710025995969772\n",
      "previous_eval_loss 0.08594104434762682\n",
      "#################\n",
      "###Epoch: 62\n",
      "Train loss 0.08267199634401887\n",
      "Valid loss 0.08582544539655958\n",
      "previous_eval_loss 0.08582544539655958\n",
      "#################\n",
      "###Epoch: 63\n",
      "Train loss 0.0824676564446202\n",
      "Valid loss 0.08666544726916722\n",
      "previous_eval_loss 0.08582544539655958\n",
      "#################\n",
      "###Epoch: 64\n",
      "Train loss 0.08228923352780165\n",
      "Valid loss 0.08584077975579671\n",
      "previous_eval_loss 0.08582544539655958\n",
      "#################\n",
      "###Epoch: 65\n",
      "Train loss 0.08120461801687877\n",
      "Valid loss 0.08485080301761627\n",
      "previous_eval_loss 0.08485080301761627\n",
      "#################\n",
      "###Epoch: 66\n",
      "Train loss 0.08009710631988666\n",
      "Valid loss 0.08588373448167529\n",
      "previous_eval_loss 0.08485080301761627\n",
      "#################\n",
      "###Epoch: 67\n",
      "Train loss 0.08098631655728375\n",
      "Valid loss 0.08498416415282659\n",
      "previous_eval_loss 0.08485080301761627\n",
      "#################\n",
      "###Epoch: 68\n",
      "Train loss 0.07984580099582672\n",
      "Valid loss 0.08664295503071376\n",
      "previous_eval_loss 0.08485080301761627\n",
      "#################\n",
      "###Epoch: 69\n",
      "Train loss 0.07938058467374907\n",
      "Valid loss 0.08450141549110413\n",
      "previous_eval_loss 0.08450141549110413\n",
      "#################\n",
      "###Epoch: 70\n",
      "Train loss 0.07915652764064295\n",
      "Valid loss 0.08457080168383461\n",
      "previous_eval_loss 0.08450141549110413\n",
      "#################\n",
      "###Epoch: 71\n",
      "Train loss 0.07863769901019556\n",
      "Valid loss 0.08463639446667262\n",
      "previous_eval_loss 0.08450141549110413\n",
      "#################\n",
      "###Epoch: 72\n",
      "Train loss 0.07848813826287235\n",
      "Valid loss 0.08578645863703319\n",
      "previous_eval_loss 0.08450141549110413\n",
      "#################\n",
      "###Epoch: 73\n",
      "Train loss 0.07918201828444446\n",
      "Valid loss 0.0841723403760365\n",
      "previous_eval_loss 0.0841723403760365\n",
      "#################\n",
      "###Epoch: 74\n",
      "Train loss 0.0774808801986553\n",
      "Valid loss 0.0845557057431766\n",
      "previous_eval_loss 0.0841723403760365\n",
      "#################\n",
      "###Epoch: 75\n",
      "Train loss 0.07750043493730051\n",
      "Valid loss 0.08320249404226031\n",
      "previous_eval_loss 0.08320249404226031\n",
      "#################\n",
      "###Epoch: 76\n",
      "Train loss 0.07743007634524945\n",
      "Valid loss 0.08377788003001894\n",
      "previous_eval_loss 0.08320249404226031\n",
      "#################\n",
      "###Epoch: 77\n",
      "Train loss 0.07659932474295299\n",
      "Valid loss 0.08535590767860413\n",
      "previous_eval_loss 0.08320249404226031\n",
      "#################\n",
      "###Epoch: 78\n",
      "Train loss 0.07727046586849072\n",
      "Valid loss 0.08441830000707082\n",
      "previous_eval_loss 0.08320249404226031\n",
      "#################\n",
      "###Epoch: 79\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.07608299398863758\n",
      "Valid loss 0.08306723620210375\n",
      "previous_eval_loss 0.08306723620210375\n",
      "#################\n",
      "###Epoch: 80\n",
      "Train loss 0.07556196771286151\n",
      "Valid loss 0.0831243848162038\n",
      "previous_eval_loss 0.08306723620210375\n",
      "#################\n",
      "###Epoch: 81\n",
      "Train loss 0.07640054628804878\n",
      "Valid loss 0.08402522972651891\n",
      "previous_eval_loss 0.08306723620210375\n",
      "#################\n",
      "###Epoch: 82\n",
      "Train loss 0.07598800902013425\n",
      "Valid loss 0.08268011254923684\n",
      "previous_eval_loss 0.08268011254923684\n",
      "#################\n",
      "###Epoch: 83\n",
      "Train loss 0.07640049799724861\n",
      "Valid loss 0.08399064838886261\n",
      "previous_eval_loss 0.08268011254923684\n",
      "#################\n",
      "###Epoch: 84\n",
      "Train loss 0.07550817452095172\n",
      "Valid loss 0.08432658974613462\n",
      "previous_eval_loss 0.08268011254923684\n",
      "#################\n",
      "###Epoch: 85\n",
      "Train loss 0.07633012947109011\n",
      "Valid loss 0.08379442031894412\n",
      "previous_eval_loss 0.08268011254923684\n",
      "#################\n",
      "###Epoch: 86\n",
      "Train loss 0.07709282829805657\n",
      "Valid loss 0.08329119426863534\n",
      "previous_eval_loss 0.08268011254923684\n",
      "#################\n",
      "###Epoch: 87\n",
      "Train loss 0.07496503409412172\n",
      "Valid loss 0.08375169868980135\n",
      "previous_eval_loss 0.08268011254923684\n",
      "#################\n",
      "###Epoch: 88\n",
      "Train loss 0.0752022374007437\n",
      "Valid loss 0.0817934370466641\n",
      "previous_eval_loss 0.0817934370466641\n",
      "#################\n",
      "###Epoch: 89\n",
      "Train loss 0.07384377579998087\n",
      "Valid loss 0.08209020112242017\n",
      "previous_eval_loss 0.0817934370466641\n",
      "#################\n",
      "###Epoch: 90\n",
      "Train loss 0.07321895990106794\n",
      "Valid loss 0.0820224764091628\n",
      "previous_eval_loss 0.0817934370466641\n",
      "#################\n",
      "###Epoch: 91\n",
      "Train loss 0.07283902251058155\n",
      "Valid loss 0.08222137178693499\n",
      "previous_eval_loss 0.0817934370466641\n",
      "#################\n",
      "###Epoch: 92\n",
      "Train loss 0.07392466951299596\n",
      "Valid loss 0.08189331314393453\n",
      "previous_eval_loss 0.0817934370466641\n",
      "#################\n",
      "###Epoch: 93\n",
      "Train loss 0.07313540384725288\n",
      "Valid loss 0.08204333324517522\n",
      "previous_eval_loss 0.0817934370466641\n",
      "#################\n",
      "###Epoch: 94\n",
      "Train loss 0.073299840092659\n",
      "Valid loss 0.08205776980945043\n",
      "previous_eval_loss 0.0817934370466641\n",
      "#################\n",
      "###Epoch: 95\n",
      "Train loss 0.0730137002688867\n",
      "Valid loss 0.08210457648549761\n",
      "previous_eval_loss 0.0817934370466641\n",
      "#################\n",
      "###Epoch: 96\n",
      "Train loss 0.0729300848863743\n",
      "Valid loss 0.08214350576911654\n",
      "previous_eval_loss 0.0817934370466641\n",
      "#################\n",
      "###Epoch: 97\n",
      "Train loss 0.07338909114952441\n",
      "Valid loss 0.08238911096538816\n",
      "previous_eval_loss 0.0817934370466641\n",
      "#################\n",
      "###Epoch: 98\n",
      "Train loss 0.07252023589831812\n",
      "Valid loss 0.08136432617902756\n",
      "previous_eval_loss 0.08136432617902756\n",
      "#################\n",
      "###Epoch: 99\n",
      "Train loss 0.07198064236177339\n",
      "Valid loss 0.08213367526020322\n",
      "previous_eval_loss 0.08136432617902756\n",
      "#################\n",
      "###Epoch: 100\n",
      "Train loss 0.07186186203250179\n",
      "Valid loss 0.08224074436085564\n",
      "previous_eval_loss 0.08136432617902756\n",
      "#################\n",
      "###Epoch: 101\n",
      "Train loss 0.071048887791457\n",
      "Valid loss 0.08060856429593903\n",
      "previous_eval_loss 0.08060856429593903\n",
      "#################\n",
      "###Epoch: 102\n",
      "Train loss 0.07086907078822453\n",
      "Valid loss 0.08227041044405528\n",
      "previous_eval_loss 0.08060856429593903\n",
      "#################\n",
      "###Epoch: 103\n",
      "Train loss 0.07130490284827021\n",
      "Valid loss 0.08174843553985868\n",
      "previous_eval_loss 0.08060856429593903\n",
      "#################\n",
      "###Epoch: 104\n",
      "Train loss 0.07019498944282532\n",
      "Valid loss 0.08107442036271095\n",
      "previous_eval_loss 0.08060856429593903\n",
      "#################\n",
      "###Epoch: 105\n",
      "Train loss 0.07050356931156582\n",
      "Valid loss 0.08116074491824422\n",
      "previous_eval_loss 0.08060856429593903\n",
      "#################\n",
      "###Epoch: 106\n",
      "Train loss 0.07108253350964298\n",
      "Valid loss 0.08133961632847786\n",
      "previous_eval_loss 0.08060856429593903\n",
      "#################\n",
      "###Epoch: 107\n",
      "Train loss 0.06985876171125306\n",
      "Valid loss 0.08078355022839137\n",
      "previous_eval_loss 0.08060856429593903\n",
      "#################\n",
      "###Epoch: 108\n",
      "Train loss 0.07021860088463183\n",
      "Valid loss 0.08070902632815498\n",
      "previous_eval_loss 0.08060856429593903\n",
      "#################\n",
      "###Epoch: 109\n",
      "Train loss 0.06956291626448985\n",
      "Valid loss 0.08095323241182736\n",
      "previous_eval_loss 0.08060856429593903\n",
      "#################\n",
      "###Epoch: 110\n",
      "Train loss 0.06948198985170435\n",
      "Valid loss 0.08094403147697449\n",
      "previous_eval_loss 0.08060856429593903\n",
      "#################\n",
      "###Epoch: 111\n",
      "Train loss 0.0698867507830814\n",
      "Valid loss 0.08161699559007372\n",
      "previous_eval_loss 0.08060856429593903\n",
      "early stop the model at Epoch:  111\n",
      "#################\n",
      "###Epoch: 0\n",
      "Train loss 0.29904419790815423\n",
      "Valid loss 0.19068204079355514\n",
      "#################\n",
      "###Epoch: 1\n",
      "Train loss 0.2059889711715557\n",
      "Valid loss 0.17769440582820348\n",
      "previous_eval_loss 0.17769440582820348\n",
      "#################\n",
      "###Epoch: 2\n",
      "Train loss 0.18428524224846451\n",
      "Valid loss 0.16584576879228866\n",
      "previous_eval_loss 0.16584576879228866\n",
      "#################\n",
      "###Epoch: 3\n",
      "Train loss 0.17145057464087451\n",
      "Valid loss 0.1567415807928358\n",
      "previous_eval_loss 0.1567415807928358\n",
      "#################\n",
      "###Epoch: 4\n",
      "Train loss 0.1644799460967382\n",
      "Valid loss 0.15131906313555582\n",
      "previous_eval_loss 0.15131906313555582\n",
      "#################\n",
      "###Epoch: 5\n",
      "Train loss 0.15831557744079167\n",
      "Valid loss 0.1466829138142722\n",
      "previous_eval_loss 0.1466829138142722\n",
      "#################\n",
      "###Epoch: 6\n",
      "Train loss 0.15313114281053897\n",
      "Valid loss 0.14308168845517294\n",
      "previous_eval_loss 0.14308168845517294\n",
      "#################\n",
      "###Epoch: 7\n",
      "Train loss 0.14819952680004966\n",
      "Valid loss 0.13937567600182124\n",
      "previous_eval_loss 0.13937567600182124\n",
      "#################\n",
      "###Epoch: 8\n",
      "Train loss 0.14545428808088656\n",
      "Valid loss 0.14227509392159327\n",
      "previous_eval_loss 0.13937567600182124\n",
      "#################\n",
      "###Epoch: 9\n",
      "Train loss 0.1418069358225222\n",
      "Valid loss 0.13400525280407496\n",
      "previous_eval_loss 0.13400525280407496\n",
      "#################\n",
      "###Epoch: 10\n",
      "Train loss 0.13781156114957951\n",
      "Valid loss 0.1290267812354224\n",
      "previous_eval_loss 0.1290267812354224\n",
      "#################\n",
      "###Epoch: 11\n",
      "Train loss 0.13398823528378098\n",
      "Valid loss 0.1249104312488011\n",
      "previous_eval_loss 0.1249104312488011\n",
      "#################\n",
      "###Epoch: 12\n",
      "Train loss 0.12906930595636368\n",
      "Valid loss 0.12224173652274269\n",
      "previous_eval_loss 0.12224173652274269\n",
      "#################\n",
      "###Epoch: 13\n",
      "Train loss 0.12905403226613998\n",
      "Valid loss 0.1215674855879375\n",
      "previous_eval_loss 0.1215674855879375\n",
      "#################\n",
      "###Epoch: 14\n",
      "Train loss 0.127106711268425\n",
      "Valid loss 0.12077111112219947\n",
      "previous_eval_loss 0.12077111112219947\n",
      "#################\n",
      "###Epoch: 15\n",
      "Train loss 0.12475481629371643\n",
      "Valid loss 0.11904839639152799\n",
      "previous_eval_loss 0.11904839639152799\n",
      "#################\n",
      "###Epoch: 16\n",
      "Train loss 0.12252454349288235\n",
      "Valid loss 0.11677762227399009\n",
      "previous_eval_loss 0.11677762227399009\n",
      "#################\n",
      "###Epoch: 17\n",
      "Train loss 0.12023497814381565\n",
      "Valid loss 0.11520705372095108\n",
      "previous_eval_loss 0.11520705372095108\n",
      "#################\n",
      "###Epoch: 18\n",
      "Train loss 0.11860695867626755\n",
      "Valid loss 0.11515489965677261\n",
      "previous_eval_loss 0.11515489965677261\n",
      "#################\n",
      "###Epoch: 19\n",
      "Train loss 0.11747664020017341\n",
      "Valid loss 0.11262700493846621\n",
      "previous_eval_loss 0.11262700493846621\n",
      "#################\n",
      "###Epoch: 20\n",
      "Train loss 0.11542734862477691\n",
      "Valid loss 0.11024664023092814\n",
      "previous_eval_loss 0.11024664023092814\n",
      "#################\n",
      "###Epoch: 21\n",
      "Train loss 0.11349681074972506\n",
      "Valid loss 0.10901855464492526\n",
      "previous_eval_loss 0.10901855464492526\n",
      "#################\n",
      "###Epoch: 22\n",
      "Train loss 0.11301435171454041\n",
      "Valid loss 0.1086068909083094\n",
      "previous_eval_loss 0.1086068909083094\n",
      "#################\n",
      "###Epoch: 23\n",
      "Train loss 0.11126300830532003\n",
      "Valid loss 0.10837853593485695\n",
      "previous_eval_loss 0.10837853593485695\n",
      "#################\n",
      "###Epoch: 24\n",
      "Train loss 0.11008533559463642\n",
      "Valid loss 0.10651920416525432\n",
      "previous_eval_loss 0.10651920416525432\n",
      "#################\n",
      "###Epoch: 25\n",
      "Train loss 0.10945327938706786\n",
      "Valid loss 0.10509557383401054\n",
      "previous_eval_loss 0.10509557383401054\n",
      "#################\n",
      "###Epoch: 26\n",
      "Train loss 0.10734832148861002\n",
      "Valid loss 0.10543664331947054\n",
      "previous_eval_loss 0.10509557383401054\n",
      "#################\n",
      "###Epoch: 27\n",
      "Train loss 0.10754008922311994\n",
      "Valid loss 0.10535590244191033\n",
      "previous_eval_loss 0.10509557383401054\n",
      "#################\n",
      "###Epoch: 28\n",
      "Train loss 0.10699389461014006\n",
      "Valid loss 0.10248350777796336\n",
      "previous_eval_loss 0.10248350777796336\n",
      "#################\n",
      "###Epoch: 29\n",
      "Train loss 0.10399826367696126\n",
      "Valid loss 0.10204730502196721\n",
      "previous_eval_loss 0.10204730502196721\n",
      "#################\n",
      "###Epoch: 30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.10281226480448688\n",
      "Valid loss 0.10025336593389511\n",
      "previous_eval_loss 0.10025336593389511\n",
      "#################\n",
      "###Epoch: 31\n",
      "Train loss 0.10239476131068335\n",
      "Valid loss 0.10125723055430821\n",
      "previous_eval_loss 0.10025336593389511\n",
      "#################\n",
      "###Epoch: 32\n",
      "Train loss 0.09990482804951845\n",
      "Valid loss 0.09926779461758477\n",
      "previous_eval_loss 0.09926779461758477\n",
      "#################\n",
      "###Epoch: 33\n",
      "Train loss 0.09986246791150835\n",
      "Valid loss 0.09986712038516998\n",
      "previous_eval_loss 0.09926779461758477\n",
      "#################\n",
      "###Epoch: 34\n",
      "Train loss 0.098957858979702\n",
      "Valid loss 0.0990869871207646\n",
      "previous_eval_loss 0.0990869871207646\n",
      "#################\n",
      "###Epoch: 35\n",
      "Train loss 0.09795929408735699\n",
      "Valid loss 0.0987225930605616\n",
      "previous_eval_loss 0.0987225930605616\n",
      "#################\n",
      "###Epoch: 36\n",
      "Train loss 0.09700653729615388\n",
      "Valid loss 0.0966583000762122\n",
      "previous_eval_loss 0.0966583000762122\n",
      "#################\n",
      "###Epoch: 37\n",
      "Train loss 0.09734821678311736\n",
      "Valid loss 0.09737756316150938\n",
      "previous_eval_loss 0.0966583000762122\n",
      "#################\n",
      "###Epoch: 38\n",
      "Train loss 0.09598631411790848\n",
      "Valid loss 0.09504352190664836\n",
      "previous_eval_loss 0.09504352190664836\n",
      "#################\n",
      "###Epoch: 39\n",
      "Train loss 0.09437131550576952\n",
      "Valid loss 0.0956757909485272\n",
      "previous_eval_loss 0.09504352190664836\n",
      "#################\n",
      "###Epoch: 40\n",
      "Train loss 0.09283974297620633\n",
      "Valid loss 0.09642832513366427\n",
      "previous_eval_loss 0.09504352190664836\n",
      "#################\n",
      "###Epoch: 41\n",
      "Train loss 0.0928378466654707\n",
      "Valid loss 0.09631604914154325\n",
      "previous_eval_loss 0.09504352190664836\n",
      "#################\n",
      "###Epoch: 42\n",
      "Train loss 0.09179073075453441\n",
      "Valid loss 0.0941682755947113\n",
      "previous_eval_loss 0.0941682755947113\n",
      "#################\n",
      "###Epoch: 43\n",
      "Train loss 0.09154013489131574\n",
      "Valid loss 0.09436203007187162\n",
      "previous_eval_loss 0.0941682755947113\n",
      "#################\n",
      "###Epoch: 44\n",
      "Train loss 0.09144027117225859\n",
      "Valid loss 0.09348106703587941\n",
      "previous_eval_loss 0.09348106703587941\n",
      "#################\n",
      "###Epoch: 45\n",
      "Train loss 0.09003582348426183\n",
      "Valid loss 0.09208354353904724\n",
      "previous_eval_loss 0.09208354353904724\n",
      "#################\n",
      "###Epoch: 46\n",
      "Train loss 0.0893782330331979\n",
      "Valid loss 0.09163823404482432\n",
      "previous_eval_loss 0.09163823404482432\n",
      "#################\n",
      "###Epoch: 47\n",
      "Train loss 0.08771808473048387\n",
      "Valid loss 0.09449554341179985\n",
      "previous_eval_loss 0.09163823404482432\n",
      "#################\n",
      "###Epoch: 48\n",
      "Train loss 0.08728416733167789\n",
      "Valid loss 0.09157212823629379\n",
      "previous_eval_loss 0.09157212823629379\n",
      "#################\n",
      "###Epoch: 49\n",
      "Train loss 0.08661650976649037\n",
      "Valid loss 0.09060898636068616\n",
      "previous_eval_loss 0.09060898636068616\n",
      "#################\n",
      "###Epoch: 50\n",
      "Train loss 0.08594020428480925\n",
      "Valid loss 0.09188008414847511\n",
      "previous_eval_loss 0.09060898636068616\n",
      "#################\n",
      "###Epoch: 51\n",
      "Train loss 0.08582032554679447\n",
      "Valid loss 0.09131257874625069\n",
      "previous_eval_loss 0.09060898636068616\n",
      "#################\n",
      "###Epoch: 52\n",
      "Train loss 0.08573111146688461\n",
      "Valid loss 0.08936818901981626\n",
      "previous_eval_loss 0.08936818901981626\n",
      "#################\n",
      "###Epoch: 53\n",
      "Train loss 0.08382767576862264\n",
      "Valid loss 0.08974627298968178\n",
      "previous_eval_loss 0.08936818901981626\n",
      "#################\n",
      "###Epoch: 54\n",
      "Train loss 0.08364460838061792\n",
      "Valid loss 0.090219432754176\n",
      "previous_eval_loss 0.08936818901981626\n",
      "#################\n",
      "###Epoch: 55\n",
      "Train loss 0.08252567880683476\n",
      "Valid loss 0.09022966027259827\n",
      "previous_eval_loss 0.08936818901981626\n",
      "#################\n",
      "###Epoch: 56\n",
      "Train loss 0.08273817295277561\n",
      "Valid loss 0.08895732355969292\n",
      "previous_eval_loss 0.08895732355969292\n",
      "#################\n",
      "###Epoch: 57\n",
      "Train loss 0.08203380582509218\n",
      "Valid loss 0.0889884318624224\n",
      "previous_eval_loss 0.08895732355969292\n",
      "#################\n",
      "###Epoch: 58\n",
      "Train loss 0.08146066080640864\n",
      "Valid loss 0.08851574680634908\n",
      "previous_eval_loss 0.08851574680634908\n",
      "#################\n",
      "###Epoch: 59\n",
      "Train loss 0.08099071239983593\n",
      "Valid loss 0.08774814116103309\n",
      "previous_eval_loss 0.08774814116103309\n",
      "#################\n",
      "###Epoch: 60\n",
      "Train loss 0.08021444937697163\n",
      "Valid loss 0.08849328117711204\n",
      "previous_eval_loss 0.08774814116103309\n",
      "#################\n",
      "###Epoch: 61\n",
      "Train loss 0.07930091768503189\n",
      "Valid loss 0.08932034777743476\n",
      "previous_eval_loss 0.08774814116103309\n",
      "#################\n",
      "###Epoch: 62\n",
      "Train loss 0.08007968851813564\n",
      "Valid loss 0.08743110724857875\n",
      "previous_eval_loss 0.08743110724857875\n",
      "#################\n",
      "###Epoch: 63\n",
      "Train loss 0.08060810742554841\n",
      "Valid loss 0.08840324197496686\n",
      "previous_eval_loss 0.08743110724857875\n",
      "#################\n",
      "###Epoch: 64\n",
      "Train loss 0.08030957425082172\n",
      "Valid loss 0.08884516251938683\n",
      "previous_eval_loss 0.08743110724857875\n",
      "#################\n",
      "###Epoch: 65\n",
      "Train loss 0.07893229137968134\n",
      "Valid loss 0.08794605412653514\n",
      "previous_eval_loss 0.08743110724857875\n",
      "#################\n",
      "###Epoch: 66\n",
      "Train loss 0.07733274278817354\n",
      "Valid loss 0.08706549555063248\n",
      "previous_eval_loss 0.08706549555063248\n",
      "#################\n",
      "###Epoch: 67\n",
      "Train loss 0.07733025815751818\n",
      "Valid loss 0.086259554539408\n",
      "previous_eval_loss 0.086259554539408\n",
      "#################\n",
      "###Epoch: 68\n",
      "Train loss 0.07728866156604555\n",
      "Valid loss 0.08628874378544944\n",
      "previous_eval_loss 0.086259554539408\n",
      "#################\n",
      "###Epoch: 69\n",
      "Train loss 0.07668847507900661\n",
      "Valid loss 0.08858567050525121\n",
      "previous_eval_loss 0.086259554539408\n",
      "#################\n",
      "###Epoch: 70\n",
      "Train loss 0.07790599349472258\n",
      "Valid loss 0.0862973758152553\n",
      "previous_eval_loss 0.086259554539408\n",
      "#################\n",
      "###Epoch: 71\n",
      "Train loss 0.07591076153847906\n",
      "Valid loss 0.08695421900068011\n",
      "previous_eval_loss 0.086259554539408\n",
      "#################\n",
      "###Epoch: 72\n",
      "Train loss 0.07532031916909748\n",
      "Valid loss 0.0859022353376661\n",
      "previous_eval_loss 0.0859022353376661\n",
      "#################\n",
      "###Epoch: 73\n",
      "Train loss 0.07616322708350641\n",
      "Valid loss 0.08588704999004092\n",
      "previous_eval_loss 0.08588704999004092\n",
      "#################\n",
      "###Epoch: 74\n",
      "Train loss 0.07536852497745443\n",
      "Valid loss 0.0865977725812367\n",
      "previous_eval_loss 0.08588704999004092\n",
      "#################\n",
      "###Epoch: 75\n",
      "Train loss 0.07461272787164759\n",
      "Valid loss 0.0857015209538596\n",
      "previous_eval_loss 0.0857015209538596\n",
      "#################\n",
      "###Epoch: 76\n",
      "Train loss 0.07522473677440926\n",
      "Valid loss 0.08575175596135003\n",
      "previous_eval_loss 0.0857015209538596\n",
      "#################\n",
      "###Epoch: 77\n",
      "Train loss 0.07423369310520313\n",
      "Valid loss 0.08542842843702861\n",
      "previous_eval_loss 0.08542842843702861\n",
      "#################\n",
      "###Epoch: 78\n",
      "Train loss 0.07426156876263795\n",
      "Valid loss 0.08580647621835981\n",
      "previous_eval_loss 0.08542842843702861\n",
      "#################\n",
      "###Epoch: 79\n",
      "Train loss 0.07438379084622418\n",
      "Valid loss 0.0853077865072659\n",
      "previous_eval_loss 0.0853077865072659\n",
      "#################\n",
      "###Epoch: 80\n",
      "Train loss 0.074033808377054\n",
      "Valid loss 0.08504295349121094\n",
      "previous_eval_loss 0.08504295349121094\n",
      "#################\n",
      "###Epoch: 81\n",
      "Train loss 0.07292220976065707\n",
      "Valid loss 0.08462130278348923\n",
      "previous_eval_loss 0.08462130278348923\n",
      "#################\n",
      "###Epoch: 82\n",
      "Train loss 0.07277043867442343\n",
      "Valid loss 0.08532574666397912\n",
      "previous_eval_loss 0.08462130278348923\n",
      "#################\n",
      "###Epoch: 83\n",
      "Train loss 0.07399508729577065\n",
      "Valid loss 0.08580303085701806\n",
      "previous_eval_loss 0.08462130278348923\n",
      "#################\n",
      "###Epoch: 84\n",
      "Train loss 0.07293709450297886\n",
      "Valid loss 0.08501400479248591\n",
      "previous_eval_loss 0.08462130278348923\n",
      "#################\n",
      "###Epoch: 85\n",
      "Train loss 0.07216727706017317\n",
      "Valid loss 0.0842881223985127\n",
      "previous_eval_loss 0.0842881223985127\n",
      "#################\n",
      "###Epoch: 86\n",
      "Train loss 0.07240583085351521\n",
      "Valid loss 0.08452476667506355\n",
      "previous_eval_loss 0.0842881223985127\n",
      "#################\n",
      "###Epoch: 87\n",
      "Train loss 0.07177498412353021\n",
      "Valid loss 0.08607345819473267\n",
      "previous_eval_loss 0.0842881223985127\n",
      "#################\n",
      "###Epoch: 88\n",
      "Train loss 0.07359325858177962\n",
      "Valid loss 0.08513910004070827\n",
      "previous_eval_loss 0.0842881223985127\n",
      "#################\n",
      "###Epoch: 89\n",
      "Train loss 0.07165242538407997\n",
      "Valid loss 0.08391551566975457\n",
      "previous_eval_loss 0.08391551566975457\n",
      "#################\n",
      "###Epoch: 90\n",
      "Train loss 0.07072822487464657\n",
      "Valid loss 0.08499202877283096\n",
      "previous_eval_loss 0.08391551566975457\n",
      "#################\n",
      "###Epoch: 91\n",
      "Train loss 0.07078885066288489\n",
      "Valid loss 0.08580330333539418\n",
      "previous_eval_loss 0.08391551566975457\n",
      "#################\n",
      "###Epoch: 92\n",
      "Train loss 0.07015655990000125\n",
      "Valid loss 0.0842806590454919\n",
      "previous_eval_loss 0.08391551566975457\n",
      "#################\n",
      "###Epoch: 93\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.07004241341793979\n",
      "Valid loss 0.08371191578251976\n",
      "previous_eval_loss 0.08371191578251976\n",
      "#################\n",
      "###Epoch: 94\n",
      "Train loss 0.0692575045481876\n",
      "Valid loss 0.08401294159037727\n",
      "previous_eval_loss 0.08371191578251976\n",
      "#################\n",
      "###Epoch: 95\n",
      "Train loss 0.06899012349270008\n",
      "Valid loss 0.0837104395031929\n",
      "previous_eval_loss 0.0837104395031929\n",
      "#################\n",
      "###Epoch: 96\n",
      "Train loss 0.06944032882650693\n",
      "Valid loss 0.08683012106588908\n",
      "previous_eval_loss 0.0837104395031929\n",
      "#################\n",
      "###Epoch: 97\n",
      "Train loss 0.07021208452405753\n",
      "Valid loss 0.08365948178938457\n",
      "previous_eval_loss 0.08365948178938457\n",
      "#################\n",
      "###Epoch: 98\n",
      "Train loss 0.06956089977864865\n",
      "Valid loss 0.08444997348955699\n",
      "previous_eval_loss 0.08365948178938457\n",
      "#################\n",
      "###Epoch: 99\n",
      "Train loss 0.06932224278096799\n",
      "Valid loss 0.0838201886841229\n",
      "previous_eval_loss 0.08365948178938457\n",
      "#################\n",
      "###Epoch: 100\n",
      "Train loss 0.06843194075756603\n",
      "Valid loss 0.08433093449899129\n",
      "previous_eval_loss 0.08365948178938457\n",
      "#################\n",
      "###Epoch: 101\n",
      "Train loss 0.06853128348787625\n",
      "Valid loss 0.08404237351247243\n",
      "previous_eval_loss 0.08365948178938457\n",
      "#################\n",
      "###Epoch: 102\n",
      "Train loss 0.06833454055918588\n",
      "Valid loss 0.08380717145545143\n",
      "previous_eval_loss 0.08365948178938457\n",
      "#################\n",
      "###Epoch: 103\n",
      "Train loss 0.06819756273870115\n",
      "Valid loss 0.08334513115031379\n",
      "previous_eval_loss 0.08334513115031379\n",
      "#################\n",
      "###Epoch: 104\n",
      "Train loss 0.06806990628441174\n",
      "Valid loss 0.08333142208201545\n",
      "previous_eval_loss 0.08333142208201545\n",
      "#################\n",
      "###Epoch: 105\n",
      "Train loss 0.06868627557048092\n",
      "Valid loss 0.08346017556531089\n",
      "previous_eval_loss 0.08333142208201545\n",
      "#################\n",
      "###Epoch: 106\n",
      "Train loss 0.06800232731081822\n",
      "Valid loss 0.08301962167024612\n",
      "previous_eval_loss 0.08301962167024612\n",
      "#################\n",
      "###Epoch: 107\n",
      "Train loss 0.06796832962168588\n",
      "Valid loss 0.0841481579201562\n",
      "previous_eval_loss 0.08301962167024612\n",
      "#################\n",
      "###Epoch: 108\n",
      "Train loss 0.06840355376954432\n",
      "Valid loss 0.08501140773296356\n",
      "previous_eval_loss 0.08301962167024612\n",
      "#################\n",
      "###Epoch: 109\n",
      "Train loss 0.07219719803995556\n",
      "Valid loss 0.08501453059060234\n",
      "previous_eval_loss 0.08301962167024612\n",
      "#################\n",
      "###Epoch: 110\n",
      "Train loss 0.06911395393587925\n",
      "Valid loss 0.08440009185246058\n",
      "previous_eval_loss 0.08301962167024612\n",
      "#################\n",
      "###Epoch: 111\n",
      "Train loss 0.0683713382868855\n",
      "Valid loss 0.08290946909359523\n",
      "previous_eval_loss 0.08290946909359523\n",
      "#################\n",
      "###Epoch: 112\n",
      "Train loss 0.06695732143190172\n",
      "Valid loss 0.08396871387958527\n",
      "previous_eval_loss 0.08290946909359523\n",
      "#################\n",
      "###Epoch: 113\n",
      "Train loss 0.06856942590739992\n",
      "Valid loss 0.08373307436704636\n",
      "previous_eval_loss 0.08290946909359523\n",
      "#################\n",
      "###Epoch: 114\n",
      "Train loss 0.06662460982247635\n",
      "Valid loss 0.08365342446735927\n",
      "previous_eval_loss 0.08290946909359523\n",
      "#################\n",
      "###Epoch: 115\n",
      "Train loss 0.06592381276466229\n",
      "Valid loss 0.08302025922707149\n",
      "previous_eval_loss 0.08290946909359523\n",
      "#################\n",
      "###Epoch: 116\n",
      "Train loss 0.0662152912053797\n",
      "Valid loss 0.08297238392489296\n",
      "previous_eval_loss 0.08290946909359523\n",
      "#################\n",
      "###Epoch: 117\n",
      "Train loss 0.066332647645915\n",
      "Valid loss 0.08366131356784276\n",
      "previous_eval_loss 0.08290946909359523\n",
      "#################\n",
      "###Epoch: 118\n",
      "Train loss 0.06660150129486013\n",
      "Valid loss 0.0834236006651606\n",
      "previous_eval_loss 0.08290946909359523\n",
      "#################\n",
      "###Epoch: 119\n",
      "Train loss 0.06594317640971255\n",
      "Valid loss 0.08370731877429145\n",
      "previous_eval_loss 0.08290946909359523\n",
      "#################\n",
      "###Epoch: 120\n",
      "Train loss 0.06566503340447391\n",
      "Valid loss 0.08331013258014407\n",
      "previous_eval_loss 0.08290946909359523\n",
      "#################\n",
      "###Epoch: 121\n",
      "Train loss 0.06508127296412433\n",
      "Valid loss 0.08240309251206261\n",
      "previous_eval_loss 0.08240309251206261\n",
      "#################\n",
      "###Epoch: 122\n",
      "Train loss 0.06543871056702402\n",
      "Valid loss 0.08294985869101115\n",
      "previous_eval_loss 0.08240309251206261\n",
      "#################\n",
      "###Epoch: 123\n",
      "Train loss 0.06547374154130618\n",
      "Valid loss 0.0829760166151183\n",
      "previous_eval_loss 0.08240309251206261\n",
      "#################\n",
      "###Epoch: 124\n",
      "Train loss 0.06535885648594962\n",
      "Valid loss 0.08251421472855977\n",
      "previous_eval_loss 0.08240309251206261\n",
      "#################\n",
      "###Epoch: 125\n",
      "Train loss 0.06470937254252257\n",
      "Valid loss 0.0836097023316792\n",
      "previous_eval_loss 0.08240309251206261\n",
      "#################\n",
      "###Epoch: 126\n",
      "Train loss 0.0657046606971158\n",
      "Valid loss 0.08388431476695198\n",
      "previous_eval_loss 0.08240309251206261\n",
      "#################\n",
      "###Epoch: 127\n",
      "Train loss 0.06531506169725347\n",
      "Valid loss 0.08254130184650421\n",
      "previous_eval_loss 0.08240309251206261\n",
      "#################\n",
      "###Epoch: 128\n",
      "Train loss 0.06433591453565492\n",
      "Valid loss 0.08249284007719584\n",
      "previous_eval_loss 0.08240309251206261\n",
      "#################\n",
      "###Epoch: 129\n",
      "Train loss 0.06477417934823919\n",
      "Valid loss 0.0828254052570888\n",
      "previous_eval_loss 0.08240309251206261\n",
      "#################\n",
      "###Epoch: 130\n",
      "Train loss 0.06401670558585061\n",
      "Valid loss 0.08310795575380325\n",
      "previous_eval_loss 0.08240309251206261\n",
      "#################\n",
      "###Epoch: 131\n",
      "Train loss 0.06419763741669832\n",
      "Valid loss 0.08280171347515923\n",
      "previous_eval_loss 0.08240309251206261\n",
      "early stop the model at Epoch:  131\n",
      "#################\n",
      "###Epoch: 0\n",
      "Train loss 0.31566831855862226\n",
      "Valid loss 0.19564982610089438\n",
      "#################\n",
      "###Epoch: 1\n",
      "Train loss 0.2163257543687467\n",
      "Valid loss 0.1806186033146722\n",
      "previous_eval_loss 0.1806186033146722\n",
      "#################\n",
      "###Epoch: 2\n",
      "Train loss 0.2003503226571613\n",
      "Valid loss 0.1731370517185756\n",
      "previous_eval_loss 0.1731370517185756\n",
      "#################\n",
      "###Epoch: 3\n",
      "Train loss 0.18377404908339182\n",
      "Valid loss 0.16416662718568528\n",
      "previous_eval_loss 0.16416662718568528\n",
      "#################\n",
      "###Epoch: 4\n",
      "Train loss 0.1710849509195045\n",
      "Valid loss 0.1576830893754959\n",
      "previous_eval_loss 0.1576830893754959\n",
      "#################\n",
      "###Epoch: 5\n",
      "Train loss 0.16234551701280805\n",
      "Valid loss 0.15239993376391275\n",
      "previous_eval_loss 0.15239993376391275\n",
      "#################\n",
      "###Epoch: 6\n",
      "Train loss 0.15787871844238704\n",
      "Valid loss 0.14806618860789708\n",
      "previous_eval_loss 0.14806618860789708\n",
      "#################\n",
      "###Epoch: 7\n",
      "Train loss 0.15330176110620852\n",
      "Valid loss 0.14312018879822322\n",
      "previous_eval_loss 0.14312018879822322\n",
      "#################\n",
      "###Epoch: 8\n",
      "Train loss 0.14765616809880291\n",
      "Valid loss 0.13758093757288797\n",
      "previous_eval_loss 0.13758093757288797\n",
      "#################\n",
      "###Epoch: 9\n",
      "Train loss 0.14285697125726277\n",
      "Valid loss 0.13289771867649897\n",
      "previous_eval_loss 0.13289771867649897\n",
      "#################\n",
      "###Epoch: 10\n",
      "Train loss 0.14147926977387182\n",
      "Valid loss 0.13285268736737116\n",
      "previous_eval_loss 0.13285268736737116\n",
      "#################\n",
      "###Epoch: 11\n",
      "Train loss 0.13857543137338427\n",
      "Valid loss 0.128881998360157\n",
      "previous_eval_loss 0.128881998360157\n",
      "#################\n",
      "###Epoch: 12\n",
      "Train loss 0.13559443338049781\n",
      "Valid loss 0.12773043662309647\n",
      "previous_eval_loss 0.12773043662309647\n",
      "#################\n",
      "###Epoch: 13\n",
      "Train loss 0.1333044218244376\n",
      "Valid loss 0.12369897322995323\n",
      "previous_eval_loss 0.12369897322995323\n",
      "#################\n",
      "###Epoch: 14\n",
      "Train loss 0.12942902385084717\n",
      "Valid loss 0.12090470641851425\n",
      "previous_eval_loss 0.12090470641851425\n",
      "#################\n",
      "###Epoch: 15\n",
      "Train loss 0.12794953695049993\n",
      "Valid loss 0.11974371863262993\n",
      "previous_eval_loss 0.11974371863262993\n",
      "#################\n",
      "###Epoch: 16\n",
      "Train loss 0.12598377273038583\n",
      "Valid loss 0.11864650888102395\n",
      "previous_eval_loss 0.11864650888102395\n",
      "#################\n",
      "###Epoch: 17\n",
      "Train loss 0.12585467127738176\n",
      "Valid loss 0.11654885006802422\n",
      "previous_eval_loss 0.11654885006802422\n",
      "#################\n",
      "###Epoch: 18\n",
      "Train loss 0.12279129028320312\n",
      "Valid loss 0.11622209634099688\n",
      "previous_eval_loss 0.11622209634099688\n",
      "#################\n",
      "###Epoch: 19\n",
      "Train loss 0.12517566371847083\n",
      "Valid loss 0.11647537563528333\n",
      "previous_eval_loss 0.11622209634099688\n",
      "#################\n",
      "###Epoch: 20\n",
      "Train loss 0.12057392713096407\n",
      "Valid loss 0.11564437725714274\n",
      "previous_eval_loss 0.11564437725714274\n",
      "#################\n",
      "###Epoch: 21\n",
      "Train loss 0.11746496127711402\n",
      "Valid loss 0.11282351719481605\n",
      "previous_eval_loss 0.11282351719481605\n",
      "#################\n",
      "###Epoch: 22\n",
      "Train loss 0.11652539560088405\n",
      "Valid loss 0.1114182812826974\n",
      "previous_eval_loss 0.1114182812826974\n",
      "#################\n",
      "###Epoch: 23\n",
      "Train loss 0.11510772892722378\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid loss 0.1124303298337119\n",
      "previous_eval_loss 0.1114182812826974\n",
      "#################\n",
      "###Epoch: 24\n",
      "Train loss 0.11426360077328152\n",
      "Valid loss 0.10929876885243825\n",
      "previous_eval_loss 0.10929876885243825\n",
      "#################\n",
      "###Epoch: 25\n",
      "Train loss 0.11327121241225137\n",
      "Valid loss 0.10864748912198204\n",
      "previous_eval_loss 0.10864748912198204\n",
      "#################\n",
      "###Epoch: 26\n",
      "Train loss 0.11152972143005442\n",
      "Valid loss 0.10833208582230977\n",
      "previous_eval_loss 0.10833208582230977\n",
      "#################\n",
      "###Epoch: 27\n",
      "Train loss 0.11130127172779154\n",
      "Valid loss 0.10836964100599289\n",
      "previous_eval_loss 0.10833208582230977\n",
      "#################\n",
      "###Epoch: 28\n",
      "Train loss 0.10973043298279797\n",
      "Valid loss 0.10648371385676521\n",
      "previous_eval_loss 0.10648371385676521\n",
      "#################\n",
      "###Epoch: 29\n",
      "Train loss 0.10902470157102302\n",
      "Valid loss 0.10619572337184634\n",
      "previous_eval_loss 0.10619572337184634\n",
      "#################\n",
      "###Epoch: 30\n",
      "Train loss 0.10862670700859141\n",
      "Valid loss 0.10654668297086443\n",
      "previous_eval_loss 0.10619572337184634\n",
      "#################\n",
      "###Epoch: 31\n",
      "Train loss 0.10689848744206959\n",
      "Valid loss 0.10391077505690711\n",
      "previous_eval_loss 0.10391077505690711\n",
      "#################\n",
      "###Epoch: 32\n",
      "Train loss 0.10557765844795439\n",
      "Valid loss 0.10306005924940109\n",
      "previous_eval_loss 0.10306005924940109\n",
      "#################\n",
      "###Epoch: 33\n",
      "Train loss 0.10557524225226154\n",
      "Valid loss 0.10529157732214246\n",
      "previous_eval_loss 0.10306005924940109\n",
      "#################\n",
      "###Epoch: 34\n",
      "Train loss 0.10446452928913964\n",
      "Valid loss 0.10149708603109632\n",
      "previous_eval_loss 0.10149708603109632\n",
      "#################\n",
      "###Epoch: 35\n",
      "Train loss 0.10231053856787858\n",
      "Valid loss 0.10107648585523878\n",
      "previous_eval_loss 0.10107648585523878\n",
      "#################\n",
      "###Epoch: 36\n",
      "Train loss 0.10182701713509029\n",
      "Valid loss 0.09935152743543897\n",
      "previous_eval_loss 0.09935152743543897\n",
      "#################\n",
      "###Epoch: 37\n",
      "Train loss 0.10117861849290354\n",
      "Valid loss 0.10016245714255742\n",
      "previous_eval_loss 0.09935152743543897\n",
      "#################\n",
      "###Epoch: 38\n",
      "Train loss 0.09923151356202585\n",
      "Valid loss 0.10038404805319649\n",
      "previous_eval_loss 0.09935152743543897\n",
      "#################\n",
      "###Epoch: 39\n",
      "Train loss 0.09900674830984187\n",
      "Valid loss 0.10312019075666155\n",
      "previous_eval_loss 0.09935152743543897\n",
      "#################\n",
      "###Epoch: 40\n",
      "Train loss 0.09985099429333652\n",
      "Valid loss 0.09890406046594892\n",
      "previous_eval_loss 0.09890406046594892\n",
      "#################\n",
      "###Epoch: 41\n",
      "Train loss 0.09744607353651966\n",
      "Valid loss 0.09948503013168063\n",
      "previous_eval_loss 0.09890406046594892\n",
      "#################\n",
      "###Epoch: 42\n",
      "Train loss 0.09671978707666751\n",
      "Valid loss 0.0976993909903935\n",
      "previous_eval_loss 0.0976993909903935\n",
      "#################\n",
      "###Epoch: 43\n",
      "Train loss 0.09563790068582252\n",
      "Valid loss 0.09658175919737134\n",
      "previous_eval_loss 0.09658175919737134\n",
      "#################\n",
      "###Epoch: 44\n",
      "Train loss 0.09590043541457918\n",
      "Valid loss 0.09686442890337535\n",
      "previous_eval_loss 0.09658175919737134\n",
      "#################\n",
      "###Epoch: 45\n",
      "Train loss 0.09511538153445279\n",
      "Valid loss 0.09651809611490794\n",
      "previous_eval_loss 0.09651809611490794\n",
      "#################\n",
      "###Epoch: 46\n",
      "Train loss 0.09419884035984676\n",
      "Valid loss 0.09632984548807144\n",
      "previous_eval_loss 0.09632984548807144\n",
      "#################\n",
      "###Epoch: 47\n",
      "Train loss 0.0934934436723038\n",
      "Valid loss 0.09544707941157478\n",
      "previous_eval_loss 0.09544707941157478\n",
      "#################\n",
      "###Epoch: 48\n",
      "Train loss 0.09213724704804244\n",
      "Valid loss 0.09645848508392062\n",
      "previous_eval_loss 0.09544707941157478\n",
      "#################\n",
      "###Epoch: 49\n",
      "Train loss 0.09145736280414793\n",
      "Valid loss 0.0940369303737368\n",
      "previous_eval_loss 0.0940369303737368\n",
      "#################\n",
      "###Epoch: 50\n",
      "Train loss 0.09033721105919944\n",
      "Valid loss 0.09343296076570239\n",
      "previous_eval_loss 0.09343296076570239\n",
      "#################\n",
      "###Epoch: 51\n",
      "Train loss 0.09002117481496599\n",
      "Valid loss 0.09451817508254733\n",
      "previous_eval_loss 0.09343296076570239\n",
      "#################\n",
      "###Epoch: 52\n",
      "Train loss 0.0901054306714623\n",
      "Valid loss 0.09484352171421051\n",
      "previous_eval_loss 0.09343296076570239\n",
      "#################\n",
      "###Epoch: 53\n",
      "Train loss 0.09022913321300789\n",
      "Valid loss 0.09237435566527503\n",
      "previous_eval_loss 0.09237435566527503\n",
      "#################\n",
      "###Epoch: 54\n",
      "Train loss 0.08720415609854239\n",
      "Valid loss 0.09384465004716601\n",
      "previous_eval_loss 0.09237435566527503\n",
      "#################\n",
      "###Epoch: 55\n",
      "Train loss 0.0880460270025112\n",
      "Valid loss 0.09227025615317481\n",
      "previous_eval_loss 0.09227025615317481\n",
      "#################\n",
      "###Epoch: 56\n",
      "Train loss 0.08696039269367854\n",
      "Valid loss 0.09222160066877093\n",
      "previous_eval_loss 0.09222160066877093\n",
      "#################\n",
      "###Epoch: 57\n",
      "Train loss 0.08718566348155339\n",
      "Valid loss 0.09183474630117416\n",
      "previous_eval_loss 0.09183474630117416\n",
      "#################\n",
      "###Epoch: 58\n",
      "Train loss 0.08611535418916631\n",
      "Valid loss 0.09121527522802353\n",
      "previous_eval_loss 0.09121527522802353\n",
      "#################\n",
      "###Epoch: 59\n",
      "Train loss 0.08585138315403903\n",
      "Valid loss 0.09112514768327985\n",
      "previous_eval_loss 0.09112514768327985\n",
      "#################\n",
      "###Epoch: 60\n",
      "Train loss 0.08542450958931888\n",
      "Valid loss 0.0907105143581118\n",
      "previous_eval_loss 0.0907105143581118\n",
      "#################\n",
      "###Epoch: 61\n",
      "Train loss 0.08483591786137333\n",
      "Valid loss 0.09004118612834386\n",
      "previous_eval_loss 0.09004118612834386\n",
      "#################\n",
      "###Epoch: 62\n",
      "Train loss 0.0834588055257444\n",
      "Valid loss 0.08976547739335469\n",
      "previous_eval_loss 0.08976547739335469\n",
      "#################\n",
      "###Epoch: 63\n",
      "Train loss 0.0832174406559379\n",
      "Valid loss 0.09002673732382911\n",
      "previous_eval_loss 0.08976547739335469\n",
      "#################\n",
      "###Epoch: 64\n",
      "Train loss 0.08331512494219674\n",
      "Valid loss 0.0911796476159777\n",
      "previous_eval_loss 0.08976547739335469\n",
      "#################\n",
      "###Epoch: 65\n",
      "Train loss 0.08205131386165265\n",
      "Valid loss 0.09199841320514679\n",
      "previous_eval_loss 0.08976547739335469\n",
      "#################\n",
      "###Epoch: 66\n",
      "Train loss 0.08193069227315762\n",
      "Valid loss 0.08922703244856425\n",
      "previous_eval_loss 0.08922703244856425\n",
      "#################\n",
      "###Epoch: 67\n",
      "Train loss 0.08122071182286297\n",
      "Valid loss 0.09015158457415444\n",
      "previous_eval_loss 0.08922703244856425\n",
      "#################\n",
      "###Epoch: 68\n",
      "Train loss 0.08193137441520337\n",
      "Valid loss 0.08885846499885831\n",
      "previous_eval_loss 0.08885846499885831\n",
      "#################\n",
      "###Epoch: 69\n",
      "Train loss 0.0804073926475313\n",
      "Valid loss 0.08799368462392262\n",
      "previous_eval_loss 0.08799368462392262\n",
      "#################\n",
      "###Epoch: 70\n",
      "Train loss 0.08109585526916716\n",
      "Valid loss 0.08861427647726876\n",
      "previous_eval_loss 0.08799368462392262\n",
      "#################\n",
      "###Epoch: 71\n",
      "Train loss 0.08048799358032367\n",
      "Valid loss 0.09012881027800697\n",
      "previous_eval_loss 0.08799368462392262\n",
      "#################\n",
      "###Epoch: 72\n",
      "Train loss 0.08018797360084674\n",
      "Valid loss 0.08801052825791496\n",
      "previous_eval_loss 0.08799368462392262\n",
      "#################\n",
      "###Epoch: 73\n",
      "Train loss 0.079386785350464\n",
      "Valid loss 0.0875455556171281\n",
      "previous_eval_loss 0.0875455556171281\n",
      "#################\n",
      "###Epoch: 74\n",
      "Train loss 0.07860734989797627\n",
      "Valid loss 0.08687257660286767\n",
      "previous_eval_loss 0.08687257660286767\n",
      "#################\n",
      "###Epoch: 75\n",
      "Train loss 0.07874066686188733\n",
      "Valid loss 0.08747641316482\n",
      "previous_eval_loss 0.08687257660286767\n",
      "#################\n",
      "###Epoch: 76\n",
      "Train loss 0.07804612980948554\n",
      "Valid loss 0.08793045473950249\n",
      "previous_eval_loss 0.08687257660286767\n",
      "#################\n",
      "###Epoch: 77\n",
      "Train loss 0.0787018487850825\n",
      "Valid loss 0.08685251751116344\n",
      "previous_eval_loss 0.08685251751116344\n",
      "#################\n",
      "###Epoch: 78\n",
      "Train loss 0.07829276141193178\n",
      "Valid loss 0.08691303219114031\n",
      "previous_eval_loss 0.08685251751116344\n",
      "#################\n",
      "###Epoch: 79\n",
      "Train loss 0.07666959034072028\n",
      "Valid loss 0.08843773284128734\n",
      "previous_eval_loss 0.08685251751116344\n",
      "#################\n",
      "###Epoch: 80\n",
      "Train loss 0.0762809883389208\n",
      "Valid loss 0.08629448605435235\n",
      "previous_eval_loss 0.08629448605435235\n",
      "#################\n",
      "###Epoch: 81\n",
      "Train loss 0.07647785682369161\n",
      "Valid loss 0.08740548363753728\n",
      "previous_eval_loss 0.08629448605435235\n",
      "#################\n",
      "###Epoch: 82\n",
      "Train loss 0.07546096874607934\n",
      "Valid loss 0.0859709062746593\n",
      "previous_eval_loss 0.0859709062746593\n",
      "#################\n",
      "###Epoch: 83\n",
      "Train loss 0.07532593166386639\n",
      "Valid loss 0.08555248592581068\n",
      "previous_eval_loss 0.08555248592581068\n",
      "#################\n",
      "###Epoch: 84\n",
      "Train loss 0.07599596127315804\n",
      "Valid loss 0.08597486253295626\n",
      "previous_eval_loss 0.08555248592581068\n",
      "#################\n",
      "###Epoch: 85\n",
      "Train loss 0.07526217483811909\n",
      "Valid loss 0.08897880464792252\n",
      "previous_eval_loss 0.08555248592581068\n",
      "#################\n",
      "###Epoch: 86\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.07595304979218377\n",
      "Valid loss 0.08650406450033188\n",
      "previous_eval_loss 0.08555248592581068\n",
      "#################\n",
      "###Epoch: 87\n",
      "Train loss 0.0751106865980007\n",
      "Valid loss 0.08562626370361873\n",
      "previous_eval_loss 0.08555248592581068\n",
      "#################\n",
      "###Epoch: 88\n",
      "Train loss 0.07435175169397283\n",
      "Valid loss 0.08586688339710236\n",
      "previous_eval_loss 0.08555248592581068\n",
      "#################\n",
      "###Epoch: 89\n",
      "Train loss 0.07532683428790835\n",
      "Valid loss 0.0859811103769711\n",
      "previous_eval_loss 0.08555248592581068\n",
      "#################\n",
      "###Epoch: 90\n",
      "Train loss 0.0747007346815533\n",
      "Valid loss 0.08639246331793922\n",
      "previous_eval_loss 0.08555248592581068\n",
      "#################\n",
      "###Epoch: 91\n",
      "Train loss 0.07399467847965381\n",
      "Valid loss 0.08618186733552388\n",
      "previous_eval_loss 0.08555248592581068\n",
      "#################\n",
      "###Epoch: 92\n",
      "Train loss 0.07436263726817237\n",
      "Valid loss 0.08725528525454658\n",
      "previous_eval_loss 0.08555248592581068\n",
      "#################\n",
      "###Epoch: 93\n",
      "Train loss 0.07444506124765785\n",
      "Valid loss 0.08669852891138621\n",
      "previous_eval_loss 0.08555248592581068\n",
      "early stop the model at Epoch:  93\n"
     ]
    }
   ],
   "source": [
    "# train different aggregators\n",
    "config.pretrain_dir = \"baseline_model\"\n",
    "splits = KFold(n_splits=config.n_split, shuffle=True, random_state=config.seed).split(train_inputs)\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(splits):\n",
    "    train_dataset = TensorDataset(train_inputs[train_idx], train_labels[train_idx])\n",
    "    train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True, num_workers=8)\n",
    "\n",
    "    valid_dataset = TensorDataset(train_inputs[val_idx], train_labels[val_idx])\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=config.batch_size, shuffle=False, num_workers=8)\n",
    "\n",
    "    train_losses, eval_losses = run(fold, train_loader, valid_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "public_df = test.query(\"seq_length == 107\").copy()\n",
    "private_df = test.query(\"seq_length == 130\").copy()\n",
    "\n",
    "public_inputs = one_hot_encoding(public_df)\n",
    "private_inputs = one_hot_encoding(private_df)\n",
    "\n",
    "public_inputs = torch.tensor(public_inputs, dtype=torch.float32)\n",
    "private_inputs = torch.tensor(private_inputs, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_short = Net(seq_len=107, pred_len=107)\n",
    "model_long = Net(seq_len=130, pred_len=130)\n",
    "\n",
    "list_public_preds = []\n",
    "list_private_preds = []\n",
    "for fold in range(5):\n",
    "    config.pretrain_dir = \"baseline_model\"\n",
    "    model_short.load_state_dict(torch.load(f'{config.pretrain_dir}/baseline_{fold}.pt'))\n",
    "    model_long.load_state_dict(torch.load(f'{config.pretrain_dir}/baseline_{fold}.pt'))\n",
    "    model_short.cuda()\n",
    "    model_long.cuda()\n",
    "    model_short.eval()\n",
    "    model_long.eval()\n",
    "\n",
    "    public_preds = model_short(public_inputs.cuda())\n",
    "    private_preds = model_long(private_inputs.cuda())\n",
    "    public_preds = public_preds.cpu().detach().numpy()\n",
    "    private_preds = private_preds.cpu().detach().numpy()\n",
    "    \n",
    "    list_public_preds.append(public_preds)\n",
    "    list_private_preds.append(private_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "public_preds = np.mean(list_public_preds, axis=0)\n",
    "private_preds = np.mean(list_private_preds, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_ls = []\n",
    "\n",
    "for df, preds in [(public_df, public_preds), (private_df, private_preds)]:\n",
    "    for i, uid in enumerate(df.id):\n",
    "        single_pred = preds[i]\n",
    "\n",
    "        single_df = pd.DataFrame(single_pred, columns=pred_cols)\n",
    "        single_df['id_seqpos'] = [f'{uid}_{x}' for x in range(single_df.shape[0])]\n",
    "\n",
    "        preds_ls.append(single_df)\n",
    "\n",
    "preds_df = pd.concat(preds_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = sample_df[['id_seqpos']].merge(preds_df, on=['id_seqpos'])\n",
    "submission.to_csv('%s/submission.csv'%config.pretrain_dir, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
