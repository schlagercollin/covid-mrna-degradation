{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ko5-LSj-fMvx",
    "papermill": {
     "duration": 0.014398,
     "end_time": "2020-09-17T02:35:46.102764",
     "exception": false,
     "start_time": "2020-09-17T02:35:46.088366",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T02:35:46.139235Z",
     "iopub.status.busy": "2020-09-17T02:35:46.138457Z",
     "iopub.status.idle": "2020-09-17T02:35:49.156939Z",
     "shell.execute_reply": "2020-09-17T02:35:49.156444Z"
    },
    "id": "-Ci0Ma0BfMvy",
    "papermill": {
     "duration": 3.039526,
     "end_time": "2020-09-17T02:35:49.157082",
     "exception": false,
     "start_time": "2020-09-17T02:35:46.117556",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/veer/covid-mrna-degradation'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import json\n",
    "import seaborn as sns\n",
    "import os\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "import plotly.express as px\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, Dataset, DataLoader, random_split\n",
    "from torch.nn import functional as F\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ib-9gDOzfMv1",
    "papermill": {
     "duration": 0.014705,
     "end_time": "2020-09-17T02:35:49.187072",
     "exception": false,
     "start_time": "2020-09-17T02:35:49.172367",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T02:35:49.224195Z",
     "iopub.status.busy": "2020-09-17T02:35:49.223544Z",
     "iopub.status.idle": "2020-09-17T02:35:49.227413Z",
     "shell.execute_reply": "2020-09-17T02:35:49.227001Z"
    },
    "id": "CAMfRo5ifMv2",
    "papermill": {
     "duration": 0.024218,
     "end_time": "2020-09-17T02:35:49.227502",
     "exception": false,
     "start_time": "2020-09-17T02:35:49.203284",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class config:\n",
    "    train_file = '/home/veer/covid-mrna-degradation/data/train.json'\n",
    "    test_file = '/home/veer/covid-mrna-degradation/data/test.json'\n",
    "    pretrain_dir = './'\n",
    "    sample_submission = '/home/veer/covid-mrna-degradation/data/sample_submission.csv'\n",
    "    learning_rate = 0.001\n",
    "    batch_size = 64\n",
    "    n_epoch = 20\n",
    "    n_split = 2\n",
    "    K = 1 # number of aggregation loop (also means number of GCN layers)\n",
    "    gcn_agg = 'mean' # aggregator function: mean, conv, lstm, pooling\n",
    "    filter_noise = True\n",
    "    seed = 1234"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j6sYKCDEfMv5",
    "papermill": {
     "duration": 0.014646,
     "end_time": "2020-09-17T02:35:49.256975",
     "exception": false,
     "start_time": "2020-09-17T02:35:49.242329",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T02:35:49.293765Z",
     "iopub.status.busy": "2020-09-17T02:35:49.293236Z",
     "iopub.status.idle": "2020-09-17T02:35:49.296872Z",
     "shell.execute_reply": "2020-09-17T02:35:49.297273Z"
    },
    "id": "7EwwSSDufMv6",
    "papermill": {
     "duration": 0.025475,
     "end_time": "2020-09-17T02:35:49.297375",
     "exception": false,
     "start_time": "2020-09-17T02:35:49.271900",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AverageMeter:\n",
    "    \"\"\"\n",
    "    Computes and stores the average and current value\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T02:35:49.335093Z",
     "iopub.status.busy": "2020-09-17T02:35:49.333554Z",
     "iopub.status.idle": "2020-09-17T02:35:49.345889Z",
     "shell.execute_reply": "2020-09-17T02:35:49.346502Z"
    },
    "id": "tN8rjf4XfMv9",
    "papermill": {
     "duration": 0.034232,
     "end_time": "2020-09-17T02:35:49.346609",
     "exception": false,
     "start_time": "2020-09-17T02:35:49.312377",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed=1234):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    \n",
    "seed_everything(config.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PWCIHIwrfMv_",
    "papermill": {
     "duration": 0.015001,
     "end_time": "2020-09-17T02:35:49.380944",
     "exception": false,
     "start_time": "2020-09-17T02:35:49.365943",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T02:35:49.441304Z",
     "iopub.status.busy": "2020-09-17T02:35:49.439899Z",
     "iopub.status.idle": "2020-09-17T02:35:49.442323Z",
     "shell.execute_reply": "2020-09-17T02:35:49.442781Z"
    },
    "id": "CHBkD2BGfMwA",
    "papermill": {
     "duration": 0.046821,
     "end_time": "2020-09-17T02:35:49.442880",
     "exception": false,
     "start_time": "2020-09-17T02:35:49.396059",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GCN(nn.Module):\n",
    "    '''\n",
    "    Implementation of one layer of GraphSAGE\n",
    "    '''\n",
    "    def __init__(self, input_dim, output_dim, aggregator='mean'):\n",
    "        super(GCN, self).__init__()\n",
    "        self.aggregator = aggregator\n",
    "        \n",
    "        if aggregator == 'mean':\n",
    "            linear_input_dim = input_dim * 2\n",
    "        elif aggregator == 'conv':\n",
    "            linear_input_dim = input_dim\n",
    "        elif aggregator == 'pooling':\n",
    "            linear_input_dim = input_dim * 2\n",
    "            self.linear_pooling = nn.Linear(input_dim, input_dim)\n",
    "        elif aggregator == 'lstm':\n",
    "            self.lstm_hidden = 128\n",
    "            linear_input_dim = input_dim + self.lstm_hidden\n",
    "            self.lstm_agg = nn.LSTM(input_dim, self.lstm_hidden, num_layers=1, batch_first=True)\n",
    "        \n",
    "        self.linear_gcn = nn.Linear(in_features=linear_input_dim, out_features=output_dim)\n",
    "        \n",
    "    def forward(self, input_, adj_matrix):\n",
    "        if self.aggregator == 'conv':\n",
    "            # set elements in diagonal of adj matrix to 1 with conv aggregator\n",
    "            idx = torch.arange(0, adj_matrix.shape[-1], out=torch.LongTensor())\n",
    "            adj_matrix[:, idx, idx] = 1\n",
    "            \n",
    "        adj_matrix = adj_matrix.type(torch.float32)\n",
    "        sum_adj = torch.sum(adj_matrix, axis=2)\n",
    "        sum_adj[sum_adj==0] = 1\n",
    "        \n",
    "        if self.aggregator == 'mean' or self.aggregator == 'conv':\n",
    "            feature_agg = torch.bmm(adj_matrix, input_)\n",
    "            feature_agg = feature_agg / sum_adj.unsqueeze(dim=2)\n",
    "            \n",
    "        elif self.aggregator == 'pooling':\n",
    "            feature_pooling = self.linear_pooling(input_)\n",
    "            feature_agg = torch.sigmoid(feature_pooling)\n",
    "            feature_agg = torch.bmm(adj_matrix, feature_agg)\n",
    "            feature_agg = feature_agg / sum_adj.unsqueeze(dim=2)\n",
    "\n",
    "        elif self.aggregator == 'lstm':\n",
    "            feature_agg = torch.zeros(input_.shape[0], input_.shape[1], self.lstm_hidden)\n",
    "            for i in range(adj_matrix.shape[1]):\n",
    "                neighbors = adj_matrix[:, i, :].unsqueeze(2) * input_\n",
    "                _, hn = self.lstm_agg(neighbors)\n",
    "                feature_agg[:, i, :] = torch.squeeze(hn[0], 0)\n",
    "                \n",
    "        if self.aggregator != 'conv':\n",
    "            feature_cat = torch.cat((input_, feature_agg), axis=2)\n",
    "        else:\n",
    "            feature_cat = feature_agg\n",
    "                \n",
    "        feature = torch.sigmoid(self.linear_gcn(feature_cat))\n",
    "        feature = feature / torch.norm(feature, p=2, dim=2).unsqueeze(dim=2)\n",
    "        \n",
    "        return feature\n",
    "        \n",
    "    \n",
    "class Net(nn.Module):\n",
    "    def __init__(self, num_embedding=14, seq_len=107, pred_len=68, dropout=0.5, \n",
    "                 embed_dim=100, hidden_dim=128, K=1, aggregator='mean'):\n",
    "        '''\n",
    "        K: number of GCN layers\n",
    "        aggregator: type of aggregator function\n",
    "        '''\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.pred_len = pred_len\n",
    "        \n",
    "        self.gcn = nn.ModuleList([GCN(3 * embed_dim, 3 * embed_dim, aggregator=aggregator) for i in range(K)])\n",
    "        \n",
    "        self.gru_layer = nn.GRU(input_size=3 * embed_dim, \n",
    "                          hidden_size=hidden_dim, \n",
    "                          num_layers=3, \n",
    "                          batch_first=True, \n",
    "                          dropout=dropout, \n",
    "                          bidirectional=True)\n",
    "        \n",
    "        self.linear_layer = nn.Linear(in_features=2 * hidden_dim, \n",
    "                                out_features=5)\n",
    "        \n",
    "    def forward(self, input_, adj_matrix):\n",
    "        #gcn\n",
    "        gcn_feature = input_\n",
    "        for gcn_layer in self.gcn:\n",
    "            gcn_feature = gcn_layer(gcn_feature, adj_matrix)\n",
    "        \n",
    "        #gru\n",
    "        gru_output, gru_hidden = self.gru_layer(gcn_feature)\n",
    "        truncated = gru_output[:, :self.pred_len]\n",
    "        \n",
    "        output = self.linear_layer(truncated)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CyUT0vsEfMwD",
    "papermill": {
     "duration": 0.014981,
     "end_time": "2020-09-17T02:35:49.473080",
     "exception": false,
     "start_time": "2020-09-17T02:35:49.458099",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T02:35:49.507398Z",
     "iopub.status.busy": "2020-09-17T02:35:49.506717Z",
     "iopub.status.idle": "2020-09-17T02:35:49.510442Z",
     "shell.execute_reply": "2020-09-17T02:35:49.509934Z"
    },
    "id": "WyGKPKapfMwE",
    "papermill": {
     "duration": 0.022267,
     "end_time": "2020-09-17T02:35:49.510525",
     "exception": false,
     "start_time": "2020-09-17T02:35:49.488258",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred_cols = ['reactivity', 'deg_Mg_pH10', 'deg_pH10', 'deg_Mg_50C', 'deg_50C']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T02:35:49.556772Z",
     "iopub.status.busy": "2020-09-17T02:35:49.556099Z",
     "iopub.status.idle": "2020-09-17T02:35:49.558941Z",
     "shell.execute_reply": "2020-09-17T02:35:49.558500Z"
    },
    "id": "_GV2vZi5fMwH",
    "papermill": {
     "duration": 0.033215,
     "end_time": "2020-09-17T02:35:49.559047",
     "exception": false,
     "start_time": "2020-09-17T02:35:49.525832",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "token2int = {x:i for i, x in enumerate('().ACGUBEHIMSX')}\n",
    "\n",
    "def get_couples(structure):\n",
    "    \"\"\"\n",
    "    For each closing parenthesis, I find the matching opening one and store their index in the couples list.\n",
    "    The assigned list is used to keep track of the assigned opening parenthesis\n",
    "    \"\"\"\n",
    "    opened = [idx for idx, i in enumerate(structure) if i == '(']\n",
    "    closed = [idx for idx, i in enumerate(structure) if i == ')']\n",
    "\n",
    "    assert len(opened) == len(closed)\n",
    "    assigned = []\n",
    "    couples = []\n",
    "\n",
    "    for close_idx in closed:\n",
    "        for open_idx in opened:\n",
    "            if open_idx < close_idx:\n",
    "                if open_idx not in assigned:\n",
    "                    candidate = open_idx\n",
    "            else:\n",
    "                break\n",
    "        assigned.append(candidate)\n",
    "        couples.append([candidate, close_idx])\n",
    "        \n",
    "    assert len(couples) == len(opened)\n",
    "    \n",
    "    return couples\n",
    "\n",
    "def build_matrix(couples, size):\n",
    "    mat = np.zeros((size, size))\n",
    "    \n",
    "    for i in range(size):  # neigbouring bases are linked as well\n",
    "        if i < size - 1:\n",
    "            mat[i, i + 1] = 1\n",
    "        if i > 0:\n",
    "            mat[i, i - 1] = 1\n",
    "    \n",
    "    for i, j in couples:\n",
    "        mat[i, j] = 1\n",
    "        mat[j, i] = 1\n",
    "        \n",
    "    return mat\n",
    "\n",
    "def convert_to_adj(structure):\n",
    "    couples = get_couples(structure)\n",
    "    mat = build_matrix(couples, len(structure))\n",
    "    return mat\n",
    "\n",
    "def preprocess_inputs(df, cols=['sequence', 'structure', 'predicted_loop_type']):\n",
    "    inputs = np.transpose(\n",
    "        np.array(\n",
    "            df[cols]\n",
    "            .applymap(lambda seq: [token2int[x] for x in seq])\n",
    "            .values\n",
    "            .tolist()\n",
    "        ),\n",
    "        (0, 2, 1)\n",
    "    )\n",
    "    \n",
    "    adj_matrix = np.array(df['structure'].apply(convert_to_adj).values.tolist())\n",
    "    \n",
    "    return inputs, adj_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T02:35:49.605738Z",
     "iopub.status.busy": "2020-09-17T02:35:49.601132Z",
     "iopub.status.idle": "2020-09-17T02:35:50.806540Z",
     "shell.execute_reply": "2020-09-17T02:35:50.806010Z"
    },
    "id": "6zuAYCKrfMwK",
    "papermill": {
     "duration": 1.231464,
     "end_time": "2020-09-17T02:35:50.806651",
     "exception": false,
     "start_time": "2020-09-17T02:35:49.575187",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_json(config.train_file, lines=True)\n",
    "\n",
    "if config.filter_noise:\n",
    "    train = train[train.signal_to_noise > 1]\n",
    "    \n",
    "test = pd.read_json(config.test_file, lines=True)\n",
    "sample_df = pd.read_csv(config.sample_submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T02:35:50.849189Z",
     "iopub.status.busy": "2020-09-17T02:35:50.848222Z",
     "iopub.status.idle": "2020-09-17T02:35:51.790209Z",
     "shell.execute_reply": "2020-09-17T02:35:51.789690Z"
    },
    "id": "1JCDE6lBfMwM",
    "papermill": {
     "duration": 0.967438,
     "end_time": "2020-09-17T02:35:51.790309",
     "exception": false,
     "start_time": "2020-09-17T02:35:50.822871",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_inputs, train_adj = preprocess_inputs(train)\n",
    "train_labels = np.array(train[pred_cols].values.tolist()).transpose((0, 2, 1))\n",
    "\n",
    "train_inputs = torch.tensor(train_inputs, dtype=torch.long)\n",
    "train_adj = torch.tensor(train_adj, dtype=torch.float32, requires_grad=False)\n",
    "train_labels = torch.tensor(train_labels, dtype=torch.float32)\n",
    "\n",
    "#embedding\n",
    "embedding_layer = nn.Embedding(num_embeddings=14, \n",
    "                                      embedding_dim=100)\n",
    "train_inputs = embedding_layer(train_inputs)\n",
    "train_inputs = torch.reshape(train_inputs, (-1, train_inputs.shape[1], train_inputs.shape[2] * train_inputs.shape[3]))\n",
    "train_inputs = train_inputs.clone().detach().requires_grad_(False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WtdIbMVNfMwP",
    "papermill": {
     "duration": 0.015575,
     "end_time": "2020-09-17T02:35:51.822063",
     "exception": false,
     "start_time": "2020-09-17T02:35:51.806488",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T02:35:51.864241Z",
     "iopub.status.busy": "2020-09-17T02:35:51.863595Z",
     "iopub.status.idle": "2020-09-17T02:35:51.867388Z",
     "shell.execute_reply": "2020-09-17T02:35:51.866938Z"
    },
    "id": "V4G72Um6fMwQ",
    "papermill": {
     "duration": 0.029786,
     "end_time": "2020-09-17T02:35:51.867469",
     "exception": false,
     "start_time": "2020-09-17T02:35:51.837683",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_fn(epoch, model, train_loader, criterion, optimizer):\n",
    "    model.train()\n",
    "    model.zero_grad()\n",
    "    train_loss = AverageMeter()\n",
    "    \n",
    "    for index, (input_, adj, label) in enumerate(train_loader):\n",
    "        input_ = input_\n",
    "        adj = adj\n",
    "        label = label\n",
    "        preds = model(input_, adj)\n",
    "        \n",
    "        loss = criterion(preds, label)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss.update(loss.item())\n",
    "    \n",
    "    print(f\"Train loss {train_loss.avg}\")\n",
    "    return train_loss.avg\n",
    "    \n",
    "def eval_fn(epoch, model, valid_loader, criterion):\n",
    "    model.eval()\n",
    "    eval_loss = AverageMeter()\n",
    "    \n",
    "    for index, (input_, adj, label) in enumerate(valid_loader):\n",
    "        input_ = input_\n",
    "        adj = adj\n",
    "        label = label\n",
    "        preds = model(input_, adj)\n",
    "        \n",
    "        loss = criterion(preds, label)\n",
    "        eval_loss.update(loss.item())\n",
    "    \n",
    "    print(f\"Valid loss {eval_loss.avg}\")\n",
    "    return eval_loss.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T02:35:51.907745Z",
     "iopub.status.busy": "2020-09-17T02:35:51.907199Z",
     "iopub.status.idle": "2020-09-17T02:35:51.909976Z",
     "shell.execute_reply": "2020-09-17T02:35:51.910355Z"
    },
    "id": "VlNCcUEsfMwS",
    "papermill": {
     "duration": 0.026891,
     "end_time": "2020-09-17T02:35:51.910453",
     "exception": false,
     "start_time": "2020-09-17T02:35:51.883562",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run(fold, train_loader, valid_loader):\n",
    "    model = Net(K=config.K, aggregator=config.gcn_agg)\n",
    "    model\n",
    "    criterion = torch.nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(params=model.parameters(), lr=config.learning_rate, weight_decay=0.0)\n",
    "    \n",
    "    train_losses = []\n",
    "    #eval_losses = []\n",
    "    for epoch in range(config.n_epoch):\n",
    "        print('#################')\n",
    "        print('###Epoch:', epoch)\n",
    "        \n",
    "        train_loss = train_fn(epoch, model, train_loader, criterion, optimizer)\n",
    "        #eval_loss = eval_fn(epoch, model, valid_loader, criterion)\n",
    "        train_losses.append(train_loss)\n",
    "        #eval_losses.append(eval_loss)\n",
    "        \n",
    "    torch.save(model.state_dict(), f'{config.pretrain_dir}/gcn_gru_{fold}.pt')\n",
    "    return train_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "execution": {
     "iopub.execute_input": "2020-09-17T02:35:51.950225Z",
     "iopub.status.busy": "2020-09-17T02:35:51.949687Z",
     "iopub.status.idle": "2020-09-17T02:57:10.834653Z",
     "shell.execute_reply": "2020-09-17T02:57:10.834165Z"
    },
    "id": "93lxSfZzfMwV",
    "outputId": "000f9b21-51a2-4fdb-a45d-98f3391269b9",
    "papermill": {
     "duration": 1278.908238,
     "end_time": "2020-09-17T02:57:10.834770",
     "exception": false,
     "start_time": "2020-09-17T02:35:51.926532",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#################\n",
      "###Epoch: 0\n",
      "Train loss 0.2419189584977699\n",
      "#################\n",
      "###Epoch: 1\n",
      "Train loss 0.173719226862445\n",
      "#################\n",
      "###Epoch: 2\n",
      "Train loss 0.15285902989633154\n",
      "#################\n",
      "###Epoch: 3\n",
      "Train loss 0.1360833186543349\n",
      "#################\n",
      "###Epoch: 4\n",
      "Train loss 0.12664806910536505\n",
      "#################\n",
      "###Epoch: 5\n",
      "Train loss 0.12047045542435213\n",
      "#################\n",
      "###Epoch: 6\n",
      "Train loss 0.11779252191384633\n",
      "#################\n",
      "###Epoch: 7\n",
      "Train loss 0.11392485937385848\n",
      "#################\n",
      "###Epoch: 8\n",
      "Train loss 0.10988418125745023\n",
      "#################\n",
      "###Epoch: 9\n",
      "Train loss 0.10620266447464626\n",
      "#################\n",
      "###Epoch: 10\n",
      "Train loss 0.10315744736880968\n",
      "#################\n",
      "###Epoch: 11\n",
      "Train loss 0.1004087608872038\n",
      "#################\n",
      "###Epoch: 12\n",
      "Train loss 0.09821595748265584\n",
      "#################\n",
      "###Epoch: 13\n",
      "Train loss 0.09511866623705084\n",
      "#################\n",
      "###Epoch: 14\n",
      "Train loss 0.09333350306207483\n",
      "#################\n",
      "###Epoch: 15\n",
      "Train loss 0.0903584724574378\n",
      "#################\n",
      "###Epoch: 16\n",
      "Train loss 0.08887814752983325\n",
      "#################\n",
      "###Epoch: 17\n",
      "Train loss 0.08654836045973228\n",
      "#################\n",
      "###Epoch: 18\n",
      "Train loss 0.08384012114821059\n",
      "#################\n",
      "###Epoch: 19\n",
      "Train loss 0.08247653101429794\n"
     ]
    }
   ],
   "source": [
    "#splits = KFold(n_splits=config.n_split, shuffle=True, random_state=config.seed).split(train_inputs)\n",
    "\n",
    "train_dataset = TensorDataset(train_inputs, train_adj, train_labels)\n",
    "train_loader = DataLoader(train_dataset, batch_size=config.batch_size, shuffle=True, num_workers=8)\n",
    "\n",
    "train_losses = run(1, train_loader, None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uyTZTcP7fMwY",
    "papermill": {
     "duration": 0.285173,
     "end_time": "2020-09-17T02:57:11.407069",
     "exception": false,
     "start_time": "2020-09-17T02:57:11.121896",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Visualize losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T02:57:11.990343Z",
     "iopub.status.busy": "2020-09-17T02:57:11.989276Z",
     "iopub.status.idle": "2020-09-17T02:57:13.092112Z",
     "shell.execute_reply": "2020-09-17T02:57:13.091668Z"
    },
    "id": "rGFCCGiufMwZ",
    "papermill": {
     "duration": 1.399938,
     "end_time": "2020-09-17T02:57:13.092212",
     "exception": false,
     "start_time": "2020-09-17T02:57:11.692274",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#fig = px.line(\n",
    "#    pd.DataFrame([train_losses, eval_losses], index=['loss', 'val_loss']).T, \n",
    "#    y=['loss', 'val_loss'], \n",
    "#    labels={'index': 'epoch', 'value': 'Mean Squared Error'}, \n",
    "#    title='Training History')\n",
    "#fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bIeneSg4fMwb",
    "papermill": {
     "duration": 0.287804,
     "end_time": "2020-09-17T02:57:13.666254",
     "exception": false,
     "start_time": "2020-09-17T02:57:13.378450",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Predict on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T02:57:14.270018Z",
     "iopub.status.busy": "2020-09-17T02:57:14.269263Z",
     "iopub.status.idle": "2020-09-17T02:57:16.372913Z",
     "shell.execute_reply": "2020-09-17T02:57:16.372360Z"
    },
    "id": "jFxaJffefMwc",
    "papermill": {
     "duration": 2.419453,
     "end_time": "2020-09-17T02:57:16.373099",
     "exception": false,
     "start_time": "2020-09-17T02:57:13.953646",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "public_df = test.query(\"seq_length == 107\").copy()\n",
    "private_df = test.query(\"seq_length == 130\").copy()\n",
    "\n",
    "public_inputs, public_adj = preprocess_inputs(public_df)\n",
    "private_inputs, private_adj = preprocess_inputs(private_df)\n",
    "\n",
    "public_inputs = torch.tensor(public_inputs, dtype=torch.long)\n",
    "private_inputs = torch.tensor(private_inputs, dtype=torch.long)\n",
    "\n",
    "public_inputs = embedding_layer(public_inputs)\n",
    "public_inputs = torch.reshape(public_inputs, (-1, public_inputs.shape[1], public_inputs.shape[2] * public_inputs.shape[3]))\n",
    "public_inputs = public_inputs.clone().detach().requires_grad_(False)\n",
    "\n",
    "private_inputs = embedding_layer(private_inputs)\n",
    "private_inputs = torch.reshape(private_inputs, (-1, private_inputs.shape[1], private_inputs.shape[2] * private_inputs.shape[3]))\n",
    "private_inputs = private_inputs.clone().detach().requires_grad_(False)\n",
    "\n",
    "\n",
    "public_adj = torch.tensor(public_adj, dtype=torch.float32, requires_grad = False)\n",
    "private_adj = torch.tensor(private_adj, dtype=torch.float32, requires_grad = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T02:57:16.956752Z",
     "iopub.status.busy": "2020-09-17T02:57:16.956025Z",
     "iopub.status.idle": "2020-09-17T02:57:18.601354Z",
     "shell.execute_reply": "2020-09-17T02:57:18.600892Z"
    },
    "id": "6tS1rVmofMwf",
    "papermill": {
     "duration": 1.940695,
     "end_time": "2020-09-17T02:57:18.601456",
     "exception": false,
     "start_time": "2020-09-17T02:57:16.660761",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3005, 130, 5)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_short = Net(seq_len=107, pred_len=107, K=config.K, aggregator=config.gcn_agg)\n",
    "model_long = Net(seq_len=130, pred_len=130, K=config.K, aggregator=config.gcn_agg)\n",
    "\n",
    "list_public_preds = []\n",
    "list_private_preds = []\n",
    "\n",
    "model_short.load_state_dict(torch.load(f'{config.pretrain_dir}/gcn_gru_{1}.pt'))\n",
    "model_long.load_state_dict(torch.load(f'{config.pretrain_dir}/gcn_gru_{1}.pt'))\n",
    "\n",
    "model_short.eval()\n",
    "model_long.eval()\n",
    "\n",
    "public_preds = model_short(public_inputs, public_adj)\n",
    "private_preds = model_long(private_inputs, private_adj)\n",
    "public_preds = public_preds.cpu().detach().numpy()\n",
    "private_preds = private_preds.cpu().detach().numpy()\n",
    "    \n",
    "list_public_preds.append(public_preds)\n",
    "list_private_preds.append(private_preds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mX7DIp7TfMwi",
    "papermill": {
     "duration": 0.49787,
     "end_time": "2020-09-17T02:57:19.388031",
     "exception": false,
     "start_time": "2020-09-17T02:57:18.890161",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Get predict results by averaging results in 5-folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T02:57:20.013829Z",
     "iopub.status.busy": "2020-09-17T02:57:20.012802Z",
     "iopub.status.idle": "2020-09-17T02:57:20.036519Z",
     "shell.execute_reply": "2020-09-17T02:57:20.035999Z"
    },
    "id": "5MUrg72LfMwi",
    "papermill": {
     "duration": 0.314347,
     "end_time": "2020-09-17T02:57:20.036666",
     "exception": false,
     "start_time": "2020-09-17T02:57:19.722319",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#public_preds = np.mean(list_public_preds, axis=0)\n",
    "#private_preds = np.mean(list_private_preds, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T02:57:20.788919Z",
     "iopub.status.busy": "2020-09-17T02:57:20.769602Z",
     "iopub.status.idle": "2020-09-17T02:57:23.725164Z",
     "shell.execute_reply": "2020-09-17T02:57:23.724663Z"
    },
    "id": "QSkZ4RuTfMwm",
    "papermill": {
     "duration": 3.399215,
     "end_time": "2020-09-17T02:57:23.725286",
     "exception": false,
     "start_time": "2020-09-17T02:57:20.326071",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#preds_ls = []\n",
    "\n",
    "#for df, preds in [(public_df, public_preds), (private_df, private_preds)]:\n",
    "#    for i, uid in enumerate(df.id):\n",
    "#        single_pred = preds[i]\n",
    "\n",
    "#        single_df = pd.DataFrame(single_pred, columns=pred_cols)\n",
    "#        single_df['id_seqpos'] = [f'{uid}_{x}' for x in range(single_df.shape[0])]\n",
    "\n",
    "#        preds_ls.append(single_df)\n",
    "\n",
    "#preds_df = pd.concat(preds_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T02:57:24.340042Z",
     "iopub.status.busy": "2020-09-17T02:57:24.338994Z",
     "iopub.status.idle": "2020-09-17T02:57:29.092796Z",
     "shell.execute_reply": "2020-09-17T02:57:29.091804Z"
    },
    "id": "kOIT-iSLfMwp",
    "papermill": {
     "duration": 5.079347,
     "end_time": "2020-09-17T02:57:29.092906",
     "exception": false,
     "start_time": "2020-09-17T02:57:24.013559",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#submission = sample_df[['id_seqpos']].merge(preds_df, on=['id_seqpos'])\n",
    "#submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T02:57:29.682995Z",
     "iopub.status.busy": "2020-09-17T02:57:29.682436Z",
     "iopub.status.idle": "2020-09-17T02:57:29.693176Z",
     "shell.execute_reply": "2020-09-17T02:57:29.693561Z"
    },
    "id": "0RT8gdb3fMwr",
    "papermill": {
     "duration": 0.306282,
     "end_time": "2020-09-17T02:57:29.693689",
     "exception": false,
     "start_time": "2020-09-17T02:57:29.387407",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#submission.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G8G1cQO138yl"
   },
   "source": [
    "# Interpretation: DeepSHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "id": "bDNChCs1fMwu",
    "papermill": {
     "duration": 0.483071,
     "end_time": "2020-09-17T02:57:30.506167",
     "exception": false,
     "start_time": "2020-09-17T02:57:30.023096",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "grad can be implicitly created only for scalar outputs",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-202-04c20a3e163c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0me\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDeepExplainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_short\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbackground_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackground_adj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mshap_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshap_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_seq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_adj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mshap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforce_plot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpected_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshap_values\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/shap/explainers/_deep/__init__.py\u001b[0m in \u001b[0;36mshap_values\u001b[0;34m(self, X, ranked_outputs, output_rank_order, check_additivity)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0mwere\u001b[0m \u001b[0mchosen\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0;34m\"top\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \"\"\"\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshap_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mranked_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_rank_order\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_additivity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_additivity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/shap/explainers/_deep/deep_pytorch.py\u001b[0m in \u001b[0;36mshap_values\u001b[0;34m(self, X, ranked_outputs, output_rank_order, check_additivity)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;31m# run attribution computation graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m                 \u001b[0mfeature_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_output_ranks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m                 \u001b[0msample_phis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_ind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjoint_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m                 \u001b[0;31m# assign the attributions to the right part of the output arrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/shap/explainers/_deep/deep_pytorch.py\u001b[0m in \u001b[0;36mgradient\u001b[0;34m(self, idx, inputs)\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m                 grad = torch.autograd.grad(selected, x,\n\u001b[0m\u001b[1;32m    122\u001b[0m                                            \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m                                            allow_unused=True)[0]\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused)\u001b[0m\n\u001b[1;32m    183\u001b[0m         \u001b[0mgrad_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m     \u001b[0mgrad_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_grads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mretain_graph\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36m_make_grads\u001b[0;34m(outputs, grads)\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"grad can be implicitly created only for scalar outputs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m                 \u001b[0mnew_grads\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreserve_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: grad can be implicitly created only for scalar outputs"
     ]
    }
   ],
   "source": [
    "import shap\n",
    "\n",
    "batch = next(iter(train_loader))\n",
    "seq, adj, _ = batch\n",
    "\n",
    "background_seq = seq[:60]\n",
    "background_adj = adj[:60]\n",
    "\n",
    "test_seq = seq[61:64]\n",
    "test_adj = adj[61:64]\n",
    "\n",
    "e = shap.DeepExplainer(model_short, [background_seq, background_adj])\n",
    "shap_values = e.shap_values([test_seq, test_adj])\n",
    "\n",
    "shap.force_plot(e.expected_value[0], shap_values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.58338577, 0.64921   , 2.189733  , 0.5451773 , 0.7296348 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpretation: LIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lime\n",
    "\n",
    "categorical_features = range(2)\n",
    "feature_names = \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 107, 3])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(test_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0, 1, 0,  ..., 0, 0, 0],\n",
       "         [1, 0, 1,  ..., 0, 0, 0],\n",
       "         [0, 1, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 1, 0],\n",
       "         [0, 0, 0,  ..., 1, 0, 1],\n",
       "         [0, 0, 0,  ..., 0, 1, 0]],\n",
       "\n",
       "        [[0, 1, 0,  ..., 0, 0, 0],\n",
       "         [1, 0, 1,  ..., 0, 0, 0],\n",
       "         [0, 1, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 1, 0],\n",
       "         [0, 0, 0,  ..., 1, 0, 1],\n",
       "         [0, 0, 0,  ..., 0, 1, 0]],\n",
       "\n",
       "        [[0, 1, 0,  ..., 0, 0, 0],\n",
       "         [1, 0, 1,  ..., 0, 0, 0],\n",
       "         [0, 1, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 1, 0],\n",
       "         [0, 0, 0,  ..., 1, 0, 1],\n",
       "         [0, 0, 0,  ..., 0, 1, 0]]])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "rna-degradation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "papermill": {
   "duration": 1310.426235,
   "end_time": "2020-09-17T02:57:32.292019",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-09-17T02:35:41.865784",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
