{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ko5-LSj-fMvx",
    "papermill": {
     "duration": 0.014398,
     "end_time": "2020-09-17T02:35:46.102764",
     "exception": false,
     "start_time": "2020-09-17T02:35:46.088366",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T02:35:46.139235Z",
     "iopub.status.busy": "2020-09-17T02:35:46.138457Z",
     "iopub.status.idle": "2020-09-17T02:35:49.156939Z",
     "shell.execute_reply": "2020-09-17T02:35:49.156444Z"
    },
    "id": "-Ci0Ma0BfMvy",
    "papermill": {
     "duration": 3.039526,
     "end_time": "2020-09-17T02:35:49.157082",
     "exception": false,
     "start_time": "2020-09-17T02:35:46.117556",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/veer/covid-mrna-degradation'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import json\n",
    "import seaborn as sns\n",
    "import os\n",
    "import random\n",
    "from tqdm.notebook import tqdm\n",
    "import plotly.express as px\n",
    "import copy\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split, KFold, StratifiedKFold\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, Dataset, DataLoader, random_split\n",
    "from torch.nn import functional as F\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ib-9gDOzfMv1",
    "papermill": {
     "duration": 0.014705,
     "end_time": "2020-09-17T02:35:49.187072",
     "exception": false,
     "start_time": "2020-09-17T02:35:49.172367",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T02:35:49.224195Z",
     "iopub.status.busy": "2020-09-17T02:35:49.223544Z",
     "iopub.status.idle": "2020-09-17T02:35:49.227413Z",
     "shell.execute_reply": "2020-09-17T02:35:49.227001Z"
    },
    "id": "CAMfRo5ifMv2",
    "papermill": {
     "duration": 0.024218,
     "end_time": "2020-09-17T02:35:49.227502",
     "exception": false,
     "start_time": "2020-09-17T02:35:49.203284",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class config:\n",
    "    train_file = '/home/veer/covid-mrna-degradation/data/train.json'\n",
    "    test_file = '/home/veer/covid-mrna-degradation/data/test.json'\n",
    "    pretrain_dir = './'\n",
    "    sample_submission = '/home/veer/covid-mrna-degradation/data/sample_submission.csv'\n",
    "    learning_rate = 0.001\n",
    "    batch_size = 64\n",
    "    n_epoch = 200\n",
    "    n_split = 5\n",
    "    K = 1 # number of aggregation loop (also means number of GCN layers)\n",
    "    gcn_agg = 'mean' # aggregator function: mean, conv, lstm, pooling\n",
    "    filter_noise = True\n",
    "    patience= 15\n",
    "    seed = 1234\n",
    "    loss_weights = torch.tensor([0.3,0.3,0.05,0.3,0.05]).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CyUT0vsEfMwD",
    "papermill": {
     "duration": 0.014981,
     "end_time": "2020-09-17T02:35:49.473080",
     "exception": false,
     "start_time": "2020-09-17T02:35:49.458099",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T02:35:49.507398Z",
     "iopub.status.busy": "2020-09-17T02:35:49.506717Z",
     "iopub.status.idle": "2020-09-17T02:35:49.510442Z",
     "shell.execute_reply": "2020-09-17T02:35:49.509934Z"
    },
    "id": "WyGKPKapfMwE",
    "papermill": {
     "duration": 0.022267,
     "end_time": "2020-09-17T02:35:49.510525",
     "exception": false,
     "start_time": "2020-09-17T02:35:49.488258",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred_cols = ['reactivity', 'deg_Mg_pH10', 'deg_pH10', 'deg_Mg_50C', 'deg_50C']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T02:35:49.556772Z",
     "iopub.status.busy": "2020-09-17T02:35:49.556099Z",
     "iopub.status.idle": "2020-09-17T02:35:49.558941Z",
     "shell.execute_reply": "2020-09-17T02:35:49.558500Z"
    },
    "id": "_GV2vZi5fMwH",
    "papermill": {
     "duration": 0.033215,
     "end_time": "2020-09-17T02:35:49.559047",
     "exception": false,
     "start_time": "2020-09-17T02:35:49.525832",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "token2int = {x:i for i, x in enumerate('().ACGUBEHIMSX')}\n",
    "\n",
    "def get_couples(structure):\n",
    "    \"\"\"\n",
    "    For each closing parenthesis, I find the matching opening one and store their index in the couples list.\n",
    "    The assigned list is used to keep track of the assigned opening parenthesis\n",
    "    \"\"\"\n",
    "    opened = [idx for idx, i in enumerate(structure) if i == '(']\n",
    "    closed = [idx for idx, i in enumerate(structure) if i == ')']\n",
    "\n",
    "    assert len(opened) == len(closed)\n",
    "    assigned = []\n",
    "    couples = []\n",
    "\n",
    "    for close_idx in closed:\n",
    "        for open_idx in opened:\n",
    "            if open_idx < close_idx:\n",
    "                if open_idx not in assigned:\n",
    "                    candidate = open_idx\n",
    "            else:\n",
    "                break\n",
    "        assigned.append(candidate)\n",
    "        couples.append([candidate, close_idx])\n",
    "        \n",
    "    assert len(couples) == len(opened)\n",
    "    \n",
    "    return couples\n",
    "\n",
    "def build_matrix(couples, size):\n",
    "    mat = np.zeros((size, size))\n",
    "    \n",
    "    for i in range(size):  # neigbouring bases are linked as well\n",
    "        if i < size - 1:\n",
    "            mat[i, i + 1] = 1\n",
    "        if i > 0:\n",
    "            mat[i, i - 1] = 1\n",
    "    \n",
    "    for i, j in couples:\n",
    "        mat[i, j] = 1\n",
    "        mat[j, i] = 1\n",
    "        \n",
    "    return mat\n",
    "\n",
    "def convert_to_adj(structure):\n",
    "    couples = get_couples(structure)\n",
    "    mat = build_matrix(couples, len(structure))\n",
    "    return mat\n",
    "\n",
    "def preprocess_inputs(df, cols=['sequence', 'structure', 'predicted_loop_type']):\n",
    "    inputs = np.transpose(\n",
    "        np.array(\n",
    "            df[cols]\n",
    "            .applymap(lambda seq: [token2int[x] for x in seq])\n",
    "            .values\n",
    "            .tolist()\n",
    "        ),\n",
    "        (0, 2, 1)\n",
    "    )\n",
    "    \n",
    "    adj_matrix = np.array(df['structure'].apply(convert_to_adj).values.tolist())\n",
    "    \n",
    "    return inputs, adj_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T02:35:49.605738Z",
     "iopub.status.busy": "2020-09-17T02:35:49.601132Z",
     "iopub.status.idle": "2020-09-17T02:35:50.806540Z",
     "shell.execute_reply": "2020-09-17T02:35:50.806010Z"
    },
    "id": "6zuAYCKrfMwK",
    "papermill": {
     "duration": 1.231464,
     "end_time": "2020-09-17T02:35:50.806651",
     "exception": false,
     "start_time": "2020-09-17T02:35:49.575187",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_json(config.train_file, lines=True)\n",
    "\n",
    "if config.filter_noise:\n",
    "    train = train[train.signal_to_noise > 1]\n",
    "    \n",
    "test = pd.read_json(config.test_file, lines=True)\n",
    "sample_df = pd.read_csv(config.sample_submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-09-17T02:35:50.849189Z",
     "iopub.status.busy": "2020-09-17T02:35:50.848222Z",
     "iopub.status.idle": "2020-09-17T02:35:51.790209Z",
     "shell.execute_reply": "2020-09-17T02:35:51.789690Z"
    },
    "id": "1JCDE6lBfMwM",
    "papermill": {
     "duration": 0.967438,
     "end_time": "2020-09-17T02:35:51.790309",
     "exception": false,
     "start_time": "2020-09-17T02:35:50.822871",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# DO ALL THIS BEFORE THE PERTURBATIONS:\n",
    "base_pairs = {3:'A', 4:'C', 5:'G', 6:'U'}\n",
    "\n",
    "train_inputs, train_adj = preprocess_inputs(train)\n",
    "train_labels = np.array(train[pred_cols].values.tolist()).transpose((0, 2, 1))\n",
    "\n",
    "num_seqs = train_inputs.shape[0]\n",
    "seq_len = train_inputs.shape[1]\n",
    "\n",
    "train_inputs = torch.tensor(train_inputs, dtype=torch.long)\n",
    "train_adj = torch.tensor(train_adj, dtype=torch.float32, requires_grad=False)\n",
    "train_labels = torch.tensor(train_labels, dtype=torch.float32)\n",
    "\n",
    "#embedding\n",
    "embedding_layer = nn.Embedding(num_embeddings=14, \n",
    "                                      embedding_dim=100)\n",
    "\n",
    "results_dict = {}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(nn.Module):\n",
    "    '''\n",
    "    Implementation of one layer of GraphSAGE\n",
    "    '''\n",
    "    def __init__(self, input_dim, output_dim, aggregator=config.gcn_agg):\n",
    "        super(GCN, self).__init__()\n",
    "        self.aggregator = aggregator\n",
    "        \n",
    "        if aggregator == 'mean':\n",
    "            linear_input_dim = input_dim * 2\n",
    "        elif aggregator == 'conv':\n",
    "            linear_input_dim = input_dim\n",
    "#         elif aggregator == 'pooling':\n",
    "#             linear_input_dim = input_dim * 2\n",
    "#             self.linear_pooling = nn.Linear(input_dim, input_dim)\n",
    "        elif aggregator == 'lstm':\n",
    "            self.lstm_hidden = 64\n",
    "            linear_input_dim = input_dim + self.lstm_hidden\n",
    "            self.lstm_agg = nn.LSTM(input_dim, self.lstm_hidden, num_layers=1, batch_first=True)\n",
    "        \n",
    "        self.linear_gcn = nn.Linear(in_features=linear_input_dim, out_features=output_dim)\n",
    "        \n",
    "    def forward(self, input_, adj_matrix):\n",
    "        if self.aggregator == 'conv':\n",
    "            # set elements in diagonal of adj matrix to 1 with conv aggregator\n",
    "            idx = torch.arange(0, adj_matrix.shape[-1], out=torch.LongTensor())\n",
    "            adj_matrix[:, idx, idx] = 1\n",
    "            \n",
    "        adj_matrix = adj_matrix.type(torch.float32)\n",
    "        sum_adj = torch.sum(adj_matrix, axis=2)\n",
    "        sum_adj[sum_adj==0] = 1\n",
    "        \n",
    "        if self.aggregator == 'mean' or self.aggregator == 'conv':\n",
    "            feature_agg = torch.bmm(adj_matrix, input_)\n",
    "            feature_agg = feature_agg / sum_adj.unsqueeze(dim=2)\n",
    "            \n",
    "#         elif self.aggregator == 'pooling':\n",
    "#             feature_pooling = self.linear_pooling(input_)\n",
    "#             feature_agg = torch.sigmoid(feature_pooling)\n",
    "#             feature_agg = torch.bmm(adj_matrix, feature_agg)\n",
    "#             feature_agg = feature_agg / sum_adj.unsqueeze(dim=2)\n",
    "\n",
    "        elif self.aggregator == 'lstm':\n",
    "            feature_agg = torch.zeros(input_.shape[0], input_.shape[1], self.lstm_hidden).cuda()\n",
    "            for i in range(adj_matrix.shape[1]):\n",
    "                neighbors = adj_matrix[:, i, :].unsqueeze(2) * input_\n",
    "                _, hn = self.lstm_agg(neighbors)\n",
    "                feature_agg[:, i, :] = torch.squeeze(hn[0], 0)\n",
    "                \n",
    "        if self.aggregator != 'conv':\n",
    "            feature_cat = torch.cat((input_, feature_agg), axis=2)\n",
    "        else:\n",
    "            feature_cat = feature_agg\n",
    "                \n",
    "        feature = torch.sigmoid(self.linear_gcn(feature_cat))\n",
    "        feature = feature / torch.norm(feature, p=2, dim=2).unsqueeze(dim=2)\n",
    "        \n",
    "        return feature\n",
    "    \n",
    "class Net(nn.Module):\n",
    "    def __init__(self, num_embedding=14, seq_len=107, pred_len=68, dropout=0.5, \n",
    "                 embed_dim=100, hidden_dim=128, K=1, aggregator='mean'):\n",
    "        '''\n",
    "        K: number of GCN layers\n",
    "        aggregator: type of aggregator function\n",
    "        '''\n",
    "        print(\"using aggregate function %s\"%aggregator)\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.pred_len = pred_len\n",
    "        self.embedding_layer = nn.Embedding(num_embeddings=num_embedding, \n",
    "                                      embedding_dim=embed_dim)\n",
    "        \n",
    "        self.gcn = nn.ModuleList([GCN(3 * embed_dim, 3 * embed_dim, aggregator=aggregator) for i in range(K)])\n",
    "        \n",
    "        self.gru_layer = nn.GRU(input_size=3 * embed_dim, \n",
    "                          hidden_size=hidden_dim, \n",
    "                          num_layers=3, \n",
    "                          batch_first=True, \n",
    "                          dropout=dropout, \n",
    "                          bidirectional=True)\n",
    "        \n",
    "        self.linear_layer = nn.Linear(in_features=2 * hidden_dim, \n",
    "                                out_features=5)\n",
    "        \n",
    "    def forward(self, input_, adj_matrix):\n",
    "        #embedding\n",
    "        embedding = self.embedding_layer(input_)\n",
    "        embedding = torch.reshape(embedding, (-1, embedding.shape[1], embedding.shape[2] * embedding.shape[3]))\n",
    "        \n",
    "        #gcn\n",
    "        gcn_feature = embedding\n",
    "        for gcn_layer in self.gcn:\n",
    "            gcn_feature = gcn_layer(gcn_feature, adj_matrix)\n",
    "        \n",
    "        #gru\n",
    "        gru_output, gru_hidden = self.gru_layer(gcn_feature)\n",
    "        truncated = gru_output[:, :self.pred_len]\n",
    "        \n",
    "        output = self.linear_layer(truncated)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using aggregate function mean\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-29-3d4fa5d14e29>:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  train_inputs_tens = torch.tensor(train_inputs, dtype=torch.long)\n"
     ]
    }
   ],
   "source": [
    "# EXECUTE THE PERTURBATIONS\n",
    "\n",
    "## Load the model\n",
    "model = Net(seq_len=107, pred_len=107, K=config.K, aggregator=config.gcn_agg)\n",
    "model.load_state_dict(torch.load('/home/veer/covid-mrna-degradation/GCN_GRU/GCN_mean_patience10/gcn_gru_4.pt'))\n",
    "\n",
    "for i in range(seq_len):\n",
    "    orig = copy.deepcopy(train_inputs[:,i,0])\n",
    "    results_dict[i] = {}\n",
    "    \n",
    "    for base in [3,4,5,6]:\n",
    "        #print(\"Base = {}; Sequence Position = {}\".format(base_pairs[base], i))\n",
    "        train_inputs[:,i,0] = base\n",
    "        \n",
    "        # Convert to embedding and get it into training format\n",
    "        train_inputs_tens = torch.tensor(train_inputs, dtype=torch.long)\n",
    "        train_inputs_tens = train_inputs_tens.clone().detach().requires_grad_(False)\n",
    "        \n",
    "        # DO FORWARD PASS. (forward pass function)\n",
    "        # results_dict[i][base_pairs[base]] = results list of 5(?)\n",
    "        model.eval()\n",
    "        preds = model(train_inputs_tens, train_adj)\n",
    "        preds = preds.cpu().detach().numpy()\n",
    "        \n",
    "        results_dict[i][base_pairs[base]] = preds\n",
    "        \n",
    "        \n",
    "    train_inputs[:,i,0] = orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.57515216, 0.5617604 , 1.7289757 , 0.5693474 , 0.7433944 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_dict[0]['A']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "rna-degradation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "papermill": {
   "duration": 1310.426235,
   "end_time": "2020-09-17T02:57:32.292019",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-09-17T02:35:41.865784",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
